{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Danish BotChat.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sharaborina/ChatBot/blob/main/Danish_text_generator%20(based%20on%20TRAX).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V299JNMyXSC3"
      },
      "source": [
        "As you know, I am going to develop a chatbot for hotel searching. A user send me in telegram some replica and the next steps are:\n",
        "\n",
        "- a function tries to extract all valuable data (dates and cities) and save it in a dictionary\n",
        "- a bot will ask until the dictionary is fill\n",
        "- if the dictionary is full, then a booking API is run and returns links to appropriate hotels.\n",
        "- then after we run generative model to answer to his words.\n",
        "\n",
        "\n",
        "In this Colab file I have trained a dialogue generator model using Trax library. \n",
        "\n",
        "Trax is an end-to-end library for deep learning that focuses on clear code and speed. It is actively used and maintained in the Google Brain team.\n",
        "\n",
        "\n",
        "# **Part 1: Exploring the MultiWoz dataset**\n",
        "\n",
        "The training is based on the MultiWoz dataset. This dataset has more than 10,000 human annotated dialogues and spans multiple domains and topics. Some dialogues include multiple domains and others include single domains. Also, there is an additional difficulty the dataset MultiWoz is in Englsh, therefore to train on a Danish model, it was decided to translate dialogues to Danish using `GoogleTranslate` API.\n",
        "\n",
        "In this section, the dataset will be loaded and explored, as well as develop a function to extract the dialogues. \n",
        "\n",
        "Let’s first install and import the modules we will be using:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xK3ojtzhrNX6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d377ae9c-ab9d-4de5-9e91-612621780e9c"
      },
      "source": [
        "# !git clone 'https://github.com/shsarv/ChatBot.git'\n",
        "# !mv ChatBot ./drive/MyDrive/ColabNotebooks/\n",
        "\n",
        "#download a vocabular\n",
        "# reader = open('/content/drive/MyDrive/ColabNotebooks/corpus/en_50k.subword', mode='r')\n",
        "# kk = 0\n",
        "# output = []\n",
        "# for line in reader:\n",
        "#   kk += 1\n",
        "#   output += line.split('\t')[0:-1]\n",
        "# print(kk)\n",
        "# reader.close()\n",
        "\n",
        "# reader = open('/content/drive/MyDrive/ColabNotebooks/corpus/en_50k_pruned.subword', mode='w', encoding='utf-8')\n",
        "# reader.write('\\n'.join(output))\n",
        "# reader.close()\n",
        "# \n",
        "# # Install JAX.\n",
        "!pip install --upgrade jax --quiet\n",
        "!pip install --upgrade jaxlib --quiet\n",
        "!pip install --upgrade trax --quiet\n",
        "!pip install trax deep_translator tensor2tensor --quiet\n",
        "\n",
        "# Make sure the Colab Runtime is set to Accelerator: TPU.\n",
        "import requests\n",
        "import os\n",
        " \n",
        "import json\n",
        "import random\n",
        "import numpy as np\n",
        "from termcolor import colored\n",
        "import trax   \n",
        "from trax import layers as tl\n",
        "from trax.supervised import training\n",
        "import tensor2tensor\n",
        "from tensor2tensor.data_generators import generator_utils\n",
        "from deep_translator import GoogleTranslator\n",
        "\n",
        "trax.fastmath.set_backend('jax') #or tensorflow-numpy\n",
        "\n",
        "# if 'TPU_DRIVER_MODE' not in globals():\n",
        "#   url = 'http://' + os.environ['COLAB_TPU_ADDR'].split(':')[0] + ':8475/requestversion/tpu_driver0.1-dev20191206'\n",
        "#   resp = requests.post(url)\n",
        "#   TPU_DRIVER_MODE = 1\n",
        "\n",
        "# The following is required to use TPU Driver as JAX's backend.\n",
        "from jax.config import config\n",
        "# config.FLAGS.jax_xla_backend = \"tpu_driver\"\n",
        "# config.FLAGS.jax_backend_target = \"grpc://\" + os.environ['COLAB_TPU_ADDR']\n",
        "print(config.FLAGS.jax_backend_target)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 45.3MB 146kB/s \n",
            "\u001b[K     |████████████████████████████████| 634kB 7.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.3MB 10.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 153kB 50.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 256kB 54.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 7.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2MB 58.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.3MB 56.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 368kB 56.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.9MB 56.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 901kB 59.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3MB 56.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.5MB 8.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 983kB 56.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 686kB 36.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 655kB 60.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 368kB 52.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 9.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 194kB 59.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.6MB 56.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 358kB 52.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 256kB 57.5MB/s \n",
            "\u001b[?25h  Building wheel for pypng (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for bz2file (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: kfac 0.2.3 has requirement tensorflow-probability==0.8, but you'll have tensorflow-probability 0.7.0 which is incompatible.\u001b[0m\n",
            "local\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQ9kvcgRCbo1",
        "outputId": "07c7b687-e232-45b3-c340-3ca93483306b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28P3X6l_ptWO"
      },
      "source": [
        "## 1.1 Define all global variables as filenames and their paths, mode of run, number of training iterations and so on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLIgNzVuoLR1"
      },
      "source": [
        "# filename of the MultiWOZ dialogue dataset\n",
        "ENGLISH_DATA_FILE = 'data.json'\n",
        "DANISH_DATA_FILE = 'danish_data.json'\n",
        "# data directory\n",
        "DATA_DIR = '/content/drive/MyDrive/ColabNotebooks/MultiWoz/'\n",
        "\n",
        "# loading of already translated array of texts which is kept inside a corresponding file.\n",
        "LOAD_UNTOKENIZED_DATA_DANISH = True\n",
        "UNTOKENIZED_DATA_DANISH_FILE = 'untokenized_data_danish.txt'\n",
        "\n",
        "#creating of a subword dictionary using UNTOKENIZED_DATA_DANISH_FILE or load from file\n",
        "CREATE_AND_SAVE_SUBWORD_VOCAB = False\n",
        "# vocabulary filename\n",
        "VOCAB_FILE = 'en_50k.subword'\n",
        "# vocabulary file directory\n",
        "VOCAB_DIR = '/content/drive/MyDrive/ColabNotebooks/MultiWoz/'\n",
        "# the size of a subword vocabulary\n",
        "VOCAB_SIZE = 50000\n",
        "\n",
        "MODEL_DIR = '/content/drive/MyDrive/ColabNotebooks/Generative_model'\n",
        "\n",
        "N_LAYERS = 6\n",
        "TRAIN_STEPS = 1000\n",
        "LOAD_MODEL = False\n",
        "TRAIN = True"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPV-S-wVPbEX"
      },
      "source": [
        "# Let's open the dataset README to see how the dialogues are stored\n",
        "# with open(DATA_DIR + '/README') as file:\n",
        "#     print(file.read())"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ln7B420p98Q"
      },
      "source": [
        "##1.2 Load the MultiWoz dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sj9ifld3oLyr"
      },
      "source": [
        "# dictionary where we will load the dialogue dataset\n",
        "DIALOGUE_ENG_DB = {}\n",
        "DIALOGUE_DB = {}\n",
        "# help function to load a JSON file\n",
        "def load_json(directory, file):\n",
        "    with open(f'{directory}/{file}') as f: \n",
        "        db = json.load(f)\n",
        "    return db\n",
        "\n",
        "def upload_json(directory, file, db):\n",
        "    with open(f'{directory}/{file}', mode='w') as f: \n",
        "        json.dump(db, f)\n",
        "\n",
        "# load the dialogue data set into our dictionary\n",
        "DIALOGUE_ENG_DB = load_json(DATA_DIR, ENGLISH_DATA_FILE)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ne1tMHrQqHVT"
      },
      "source": [
        "#1.3 Exploring of dataset, investigation of its structure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udMeNsZPoOU_",
        "outputId": "8cd68e4f-f940-4c99-adaa-f7c21e94321e"
      },
      "source": [
        "print(f'The number of dialogues is: {len(DIALOGUE_ENG_DB)}')\n",
        "print('The list of different dialogues', list(DIALOGUE_ENG_DB.keys())[0:7])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of dialogues is: 10438\n",
            "The list of different dialogues ['SNG01856.json', 'SNG0129.json', 'PMUL1635.json', 'MUL2168.json', 'SNG0073.json', 'SNG01445.json', 'MUL2105.json']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlpUI09BoTiB",
        "outputId": "c5f5597b-04e3-424a-e6dd-4f078cf2c4e3"
      },
      "source": [
        "# Let's see what keys are stored in the first file above\n",
        "file = 'SNG01856.json'\n",
        "print(DIALOGUE_ENG_DB[file].keys())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['goal', 'log'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dZvzilqooby",
        "outputId": "3a075514-ddd5-4255-a39f-74b24b4d35ce"
      },
      "source": [
        "# 'goal' keeps the metadata of the conversation\n",
        "DIALOGUE_ENG_DB[file]['goal'] "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'attraction': {},\n",
              " 'hospital': {},\n",
              " 'hotel': {'book': {'day': 'tuesday',\n",
              "   'invalid': False,\n",
              "   'people': '6',\n",
              "   'pre_invalid': True,\n",
              "   'stay': '2'},\n",
              "  'fail_book': {'stay': '3'},\n",
              "  'fail_info': {},\n",
              "  'info': {'internet': 'yes',\n",
              "   'parking': 'yes',\n",
              "   'pricerange': 'cheap',\n",
              "   'type': 'hotel'}},\n",
              " 'message': [\"You are looking for a <span class='emphasis'>place to stay</span>. The hotel should be in the <span class='emphasis'>cheap</span> price range and should be in the type of <span class='emphasis'>hotel</span>\",\n",
              "  \"The hotel should <span class='emphasis'>include free parking</span> and should <span class='emphasis'>include free wifi</span>\",\n",
              "  \"Once you find the <span class='emphasis'>hotel</span> you want to book it for <span class='emphasis'>6 people</span> and <span class='emphasis'>3 nights</span> starting from <span class='emphasis'>tuesday</span>\",\n",
              "  \"If the booking fails how about <span class='emphasis'>2 nights</span>\",\n",
              "  \"Make sure you get the <span class='emphasis'>reference number</span>\"],\n",
              " 'police': {},\n",
              " 'restaurant': {},\n",
              " 'taxi': {},\n",
              " 'topic': {'attraction': False,\n",
              "  'booking': False,\n",
              "  'general': False,\n",
              "  'hospital': False,\n",
              "  'hotel': False,\n",
              "  'police': False,\n",
              "  'restaurant': False,\n",
              "  'taxi': False,\n",
              "  'train': False},\n",
              " 'train': {}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgYQyAqkoo7r",
        "outputId": "2b83d7ff-ff7c-4809-d23e-d73bacd9633a"
      },
      "source": [
        "# get first element of the log list which corresponds to one replica of a dialogue.\n",
        "DIALOGUE_ENG_DB[file]['log'][0]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dialog_act': {'Hotel-Inform': [['Type', 'hotel'], ['Price', 'cheap']]},\n",
              " 'metadata': {},\n",
              " 'span_info': [['Hotel-Inform', 'Type', 'hotel', 20, 20],\n",
              "  ['Hotel-Inform', 'Price', 'cheap', 10, 10]],\n",
              " 'text': 'am looking for a place to to stay that has cheap price range it should be in a type of hotel'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1-6KqlPouSM",
        "outputId": "0000e850-00b2-4c06-c604-a4238c6e6246"
      },
      "source": [
        "# Let's see the first 2 replicas of a dialogue\n",
        "print(' Person 1: ', DIALOGUE_ENG_DB[file]['log'][0]['text'])\n",
        "print(' Person 2: ', DIALOGUE_ENG_DB[file]['log'][1]['text'])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Person 1:  am looking for a place to to stay that has cheap price range it should be in a type of hotel\n",
            " Person 2:  Okay, do you have a specific area you want to stay in?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0zBcQLuoyWp"
      },
      "source": [
        "# this function helps us to save conversation to a long string with Person 1 and Person 2 delimiters.\n",
        "def get_conversation(file, data_db):\n",
        "    '''\n",
        "    Args:\n",
        "        file (string): filename of the dialogue file saved as json\n",
        "        data_db (dict): dialogue database\n",
        "    \n",
        "    Returns:\n",
        "        string: A string containing the 'text' fields of  data[file]['log'][x]\n",
        "    '''\n",
        "    \n",
        "    # initialize empty string\n",
        "    result = ''\n",
        "    \n",
        "    # get length of file's log list\n",
        "    len_msg_log = len(data_db[file]['log'])\n",
        "    \n",
        "    # set the delimiter strings\n",
        "    delimiter_1 = ' Person 1: '\n",
        "    delimiter_2 = ' Person 2: '\n",
        "    \n",
        "    # loop over the file's log list\n",
        "    for i in range(len_msg_log):\n",
        "        \n",
        "    ### START CODE HERE (REPLACE INSTANCES OF 'None' WITH YOUR CODE) ###\n",
        "    \n",
        "        # get i'th element of file log list\n",
        "        cur_log = data_db[file]['log'][i]['text'].replace('\\n', ' ').replace('\\r', ' ')\n",
        "        \n",
        "        # check if i is even\n",
        "        if i%2 == 0:                   \n",
        "            # append the 1st delimiter string\n",
        "            result += delimiter_1\n",
        "        else: \n",
        "            # append the 2nd delimiter string\n",
        "            result += delimiter_2\n",
        "        \n",
        "        # append the message text from the log\n",
        "        result += cur_log\n",
        "    \n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    return result"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QV41XxQhimmI"
      },
      "source": [
        "# #Translate Database:\n",
        "# \n",
        "# def translate_db(data_db):\n",
        "#   for file, val in data_db.items():\n",
        "#     for i in range(len(data_db[file]['log'])):\n",
        "#       src = data_db[file]['log'][i]['text']\n",
        "#       # print('src=', src)\n",
        "#       target = GoogleTranslator(source='auto', target='da').translate(src)\n",
        "#       data_db[file]['log'][i]['text'] = target\n",
        "#       # print(target)\n",
        "#   return data_db\n",
        "\n",
        "# DIALOGUE_DB = translate_db(DIALOGUE_ENG_DB)\n",
        "\n",
        "# upload_json(DATA_DIR, DANISH_DATA_FILE, DIALOGUE_DB)\n",
        "DIALOGUE_DB = DIALOGUE_ENG_DB"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNY03L2Ro4e-"
      },
      "source": [
        "conversation = get_conversation(file, DIALOGUE_DB)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqb-TB6Co7Of",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e7c6886-b31d-40a1-cb39-0394d24c121c"
      },
      "source": [
        "# this function beautifully prints a conversation between two people.\n",
        "def print_conversation(conversation):\n",
        "    \n",
        "    if type(conversation) == list:\n",
        "      for i,c in enumerate(conversation):\n",
        "        print(\"Dialogue #{}\".format(i+1))\n",
        "        print_conversation(c)\n",
        "        print(\"\\n\")\n",
        "    else:\n",
        "      delimiter_1 = 'Person 1: '\n",
        "      delimiter_2 = 'Person 2: '\n",
        "      \n",
        "      split_list_d1 = conversation.split(delimiter_1)\n",
        "      \n",
        "      for sublist in split_list_d1[1:]:\n",
        "          split_list_d2 = sublist.split(delimiter_2)\n",
        "          print(colored(f'Person 1: {split_list_d2[0]}', 'red'))\n",
        "          \n",
        "          if len(split_list_d2) > 1:\n",
        "              print(colored(f'Person 2: {split_list_d2[1]}', 'green'))\n",
        "\n",
        "            \n",
        "print_conversation(conversation)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mPerson 1: am looking for a place to to stay that has cheap price range it should be in a type of hotel \u001b[0m\n",
            "\u001b[32mPerson 2: Okay, do you have a specific area you want to stay in? \u001b[0m\n",
            "\u001b[31mPerson 1: no, i just need to make sure it's cheap. oh, and i need parking \u001b[0m\n",
            "\u001b[32mPerson 2: I found 1 cheap hotel for you that includes parking. Do you like me to book it? \u001b[0m\n",
            "\u001b[31mPerson 1: Yes, please. 6 people 3 nights starting on tuesday. \u001b[0m\n",
            "\u001b[32mPerson 2: I am sorry but I wasn't able to book that for you for Tuesday. Is there another day you would like to stay or perhaps a shorter stay? \u001b[0m\n",
            "\u001b[31mPerson 1: how about only 2 nights. \u001b[0m\n",
            "\u001b[32mPerson 2: Booking was successful. Reference number is : 7GAWK763. Anything else I can do for you? \u001b[0m\n",
            "\u001b[31mPerson 1: No, that will be all. Good bye. \u001b[0m\n",
            "\u001b[32mPerson 2: Thank you for using our services.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XSVccXWsYUI"
      },
      "source": [
        "# **Part 2: Preprocessing and translation**\n",
        "In this section, I prepare the data for training, namely put the whole conversation to the `untokenized_data` list. Thus, each element of this list corresponds to one dialogue. If you don't have this list, then it can be created (`LOAD_UNTOKENIZED_DANISH` should be `False`), otherwise it is allowed to load from the `DATA_DIR + UNTOKENIZED_DATA_DANISH_FILE` (`LOAD_UNTOKENIZED_DANISH` should be `True`). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04ulPB2jRlZ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a953d86d-bb1e-4f22-f3d7-2773c209bfa6"
      },
      "source": [
        "# Translate text\n",
        "def translate(text, target='da'):\n",
        "  if type(text) == list:\n",
        "    out = []\n",
        "    for t in text:\n",
        "      print(t)\n",
        "      out.append(GoogleTranslator(source='auto', target=target).translate(t))\n",
        "    return out\n",
        "  return GoogleTranslator(source='auto', target=target).translate(text)\n",
        "\n",
        "\n",
        "if not LOAD_UNTOKENIZED_DATA_DANISH:\n",
        "  # the keys are the file names\n",
        "  all_files = DIALOGUE_DB.keys()\n",
        "\n",
        "  # initialize empty list\n",
        "  untokenized_data = []\n",
        "\n",
        "  # loop over all files\n",
        "  for file in all_files:\n",
        "      # this is the graded function you coded\n",
        "      # returns a string delimited by Person 1 and Person 2\n",
        "      result = get_conversation(file, DIALOGUE_DB)\n",
        "      translated = translate(result, target='da')\n",
        "      # append to the list\n",
        "      untokenized_data.append(translated)\n",
        "\n",
        "  #save the processed file\n",
        "  upload_json(DATA_DIR, UNTOKENIZED_DATA_DANISH_FILE, untokenized_data)\n",
        "  # print the first two dialogues to check if it's the same as the one we got before\n",
        "  print_conversation(untokenized_data[0:2])\n",
        "else: # read the untokenized_data list from a file\n",
        "  untokenized_data = load_json(DATA_DIR, UNTOKENIZED_DATA_DANISH_FILE)\n",
        "  print_conversation(untokenized_data[0:2])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dialogue #1\n",
            "\u001b[31mPerson 1: er på udkig efter et sted at bo, der har en billig prisinterval, det skal være i en type hotel \u001b[0m\n",
            "\u001b[32mPerson 2: Okay, har du et bestemt område, du vil bo i? \u001b[0m\n",
            "\u001b[31mPerson 1: nej, jeg skal bare sørge for, at det er billigt. åh, og jeg har brug for parkering \u001b[0m\n",
            "\u001b[32mPerson 2: Jeg fandt et billigt hotel til dig, der inkluderer parkering. Kan du lide, at jeg bestiller det? \u001b[0m\n",
            "\u001b[31mPerson 1: Ja tak. 6 personer 3 nætter startende på tirsdag. \u001b[0m\n",
            "\u001b[32mPerson 2: Jeg er ked af det, men jeg kunne ikke booke det til dig til tirsdag. Er der en anden dag, du gerne vil bo, eller måske et kortere ophold? \u001b[0m\n",
            "\u001b[31mPerson 1: hvad med kun 2 nætter. \u001b[0m\n",
            "\u001b[32mPerson 2: Booking lykkedes. Reference nummer er: 7GAWK763. Noget andet jeg kan gøre for dig? \u001b[0m\n",
            "\u001b[31mPerson 1: Nej, det er alt. Farvel. \u001b[0m\n",
            "\u001b[32mPerson 2: Tak fordi du bruger vores tjenester.\u001b[0m\n",
            "\n",
            "\n",
            "Dialogue #2\n",
            "\u001b[31mPerson 1: Hej, jeg er blevet røvet. Kan du hjælpe mig med at komme i kontakt med politiet? \u001b[0m\n",
            "\u001b[32mPerson 2: Parkside Police Station er i Parkside, Cambridge. Deres nummer er 01223358966. Er der noget andet, jeg kan gøre for dig? \u001b[0m\n",
            "\u001b[31mPerson 1: Kan jeg også have postnummeret? \u001b[0m\n",
            "\u001b[32mPerson 2: Postnummeret til Parkside Police Station er CB11JG. Kan jeg hjælpe dig med noget andet? \u001b[0m\n",
            "\u001b[31mPerson 1: Var Parkside adressen på politistationen? Hvis ikke, kan jeg få adressen venligst? \u001b[0m\n",
            "\u001b[32mPerson 2: Ja, Parkside er adressen. \u001b[0m\n",
            "\u001b[31mPerson 1: Tak, det vil være alt for nu. \u001b[0m\n",
            "\u001b[32mPerson 2: Fantastisk. Tak, fordi du kontaktede Cambridge Towninfo Centre. \u001b[0m\n",
            "\u001b[31mPerson 1: Du var fantastisk. Farvel. \u001b[0m\n",
            "\u001b[32mPerson 2: Vi hjælper gerne. Hav en god dag!\u001b[0m\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtwbIVniYJqi"
      },
      "source": [
        "## 2.1 Creating of subword vocabulary\n",
        "The experiments in the field of NLP show us that training on subwords works better than training on words. Therefore here we create a vocabulary of subwords and save it in `VOCAB_DIR/VOCAB_FILE`using `get_or_generate_txt_vocab` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-w6euI3dYI0x"
      },
      "source": [
        "if CREATE_AND_SAVE_SUBWORD_VOCAB:\n",
        "  !rm -rf $VOCAB_DIR/$VOCAB_FILE\n",
        "  generator_utils.get_or_generate_txt_vocab(VOCAB_DIR, VOCAB_FILE, VOCAB_SIZE, DATA_DIR + UNTOKENIZED_DATA_DANISH_FILE)\n",
        "  print(\"The vocab is succesfully created and saved as {}/{}\".format(VOCAB_DIR, VOCAB_FILE))"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y96IJkvhXp1g"
      },
      "source": [
        "## 2.2 Splitting into train and test data\n",
        "To develop a sustainable and reliable model, let us split the list to a train and eval dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgoGrDH3XnXf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd7fe411-4827-463e-c6f8-a6a9938c1cd7"
      },
      "source": [
        "# shuffle the list we generated above\n",
        "random.shuffle(untokenized_data)\n",
        "\n",
        "# define a cutoff (5% of the total length for this assignment)\n",
        "# convert to int because we will use it as a list index\n",
        "cut_off = int(len(untokenized_data) * .1)\n",
        "\n",
        "# slice the list. the last elements after the cut_off value will be the eval set. the rest is for training. \n",
        "train_data, eval_data = untokenized_data[:-cut_off], untokenized_data[-cut_off:]\n",
        "\n",
        "print(f'number of conversations in the data set: {len(untokenized_data)}')\n",
        "print(f'number of conversations in train set: {len(train_data)}')\n",
        "print(f'number of conversations in eval set: {len(eval_data)}')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of conversations in the data set: 10438\n",
            "number of conversations in train set: 9395\n",
            "number of conversations in eval set: 1043\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNuakRDHXs2y"
      },
      "source": [
        "# **2.1 Tokenizing, batching with bucketing**\n",
        "We can now proceed in generating tokenized batches of our data. Let’s first define a utility generator function to yield elements from our datasets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijCLSjD0XtRP"
      },
      "source": [
        "def stream(data):\n",
        "    # loop over the entire data\n",
        "    while True:\n",
        "        # get a random element\n",
        "        d = random.choice(data)\n",
        "        # yield a tuple pair of identical values \n",
        "        # (i.e. our inputs to the model will also be our targets during training)\n",
        "        yield (d, d)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADJSIbKJXtai"
      },
      "source": [
        "Now let’s define our data pipeline for tokenizing and batching our data. As in the previous assignments, we will bucket by length and also have an upper bound on the token length."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRDpUEVEXtpZ"
      },
      "source": [
        "# trax allows us to use combinators to generate our data pipeline\n",
        "data_pipeline = trax.data.Serial(\n",
        "    # randomizes to avoid bias in the way data is displayed\n",
        "    trax.data.Shuffle(),\n",
        "    \n",
        "    #Tokenizes using a subword dict, it breaks words into common prefixes and suffixes for better generalization\n",
        "    trax.data.Tokenize(vocab_dir=VOCAB_DIR,\n",
        "                       vocab_file=VOCAB_FILE),\n",
        "    \n",
        "    # filter too long sequences\n",
        "    trax.data.FilterByLength(1024),\n",
        "    \n",
        "    # bucket by length\n",
        "    trax.data.BucketByLength(boundaries=[128, 256,  512, 1024],\n",
        "                             batch_sizes=[16, 8,    4,   2, 1]), #BE CAREFUL!\n",
        "                              #  batch_sizes=[128, 64,    32,   16, 8]),\n",
        "                                # batch_sizes=[32, 16,    8,   4, 2]), #BE CAREFUL!\n",
        "    # add loss weights but do not add it to the padding tokens (i.e. 0)\n",
        "    trax.data.AddLossWeights(id_to_mask=0)\n",
        ")\n",
        "\n",
        "# apply the data pipeline to our train and eval sets\n",
        "train_stream = data_pipeline(stream(train_data))\n",
        "eval_stream = data_pipeline(stream(eval_data))"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79pJJNuRX2EF"
      },
      "source": [
        "Peek into the train stream."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2Opzl5qXsER",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c050695-c16f-4e64-dcce-c82964a379f2"
      },
      "source": [
        "# the stream generators will yield (input, target, weights). let's just grab the input for inspection\n",
        "inp, _, _ = next(train_stream)\n",
        "\n",
        "# print the shape. format is (batch size, token length)\n",
        "print(\"input shape: \", inp.shape)\n",
        "\n",
        "# detokenize the first element\n",
        "\n",
        "print(trax.data.detokenize(inp[0], vocab_dir=VOCAB_DIR, vocab_file=VOCAB_FILE))\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input shape:  (2, 1024)\n",
            "Person 1: Jeg har brug for et hotelværelse i nærheden af ​​Cambridge på fredag. Kan du hjælpe? Person 2: Du valgte attraktion, og hotellerne kommer ikke op. Jeg kan hjælpe med attraktioner. Person 1: Jeg vil gerne have en anbefaling til en attraktion at besøge i centret tak. Person 2: Det afhænger af, hvad du kan lide - kan du lide museer? Kollegier? Musik? Lad mig vide, så jeg kan anbefale noget Person 1: Jeg er ikke særlig. Jeg leder bare efter noget at gøre. Er der noget, som du kan anbefale som en, du ikke vil gå glip af, mens du er i byen? Person 2: Vi har en fantastisk biograf her i byen. Det kaldes Vue Cinema. Det er i centrum af byen. Ville det lyde som noget, du ville være interesseret i? Person 1: Ja, kan jeg få adresse og telefonnummer? Person 2: Sikker! De er placeret på The Grafton Center, East Road, og deres telefonnummer er 08712240240. Kan jeg hjælpe dig med noget andet? Person 1: Jeg er også interesseret i at finde et tog til Cambridge fra Norwich på torsdag. Person 2: Vi har 19 tog, der opfylder dine kriterier. Vil du indsnævre det efter afgangstid eller ankomsttid? Person 1: Jeg har brug for at toget kører efter kl. 15.30. Person 2: Jeg har i alt ni poster. Vil du gerne indsnævre det? Eller har jeg et tog kl. 15:36 eller kl. 16:36? Person 1: 15 36 er god. book til 5 venligst Person 2: Jeg har fået booket dine billetter. Brug for et sted at bo? Person 1: Må jeg have referencenummeret? Person 2: Jeg får det referencenummer til dig. Person 1: Okay ... har du referencenummeret endnu? Person 2: Kan du booke det til mig og få et referencenummer?<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFD380fbYn5_"
      },
      "source": [
        "# Part 3: ReformerLM Training\n",
        "Let's use the pre-built model which is already implemented in Trax.\n",
        "Below a wrapper function is implemented that returns a Reformer Language Model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5y3LB4oX806"
      },
      "source": [
        "def ReformerLM(vocab_size=VOCAB_SIZE, n_layers=2, mode='train', attention_type=tl.SelfAttention):\n",
        "    \"\"\"\n",
        "    Args: \n",
        "        vocab_size (int): size of the vocabulary\n",
        "        n_layers (int): number of decoder layers\n",
        "        mode (string): setting of the model which can be 'train', 'eval', or 'predict' \n",
        "        attention_type(class): attention class to use \n",
        "    Returns: \n",
        "        model (ReformerLM): a reformer language model implemented in Trax\n",
        "    \"\"\"    \n",
        "    \n",
        "    ### START CODE HERE (REPLACE INSTANCES OF 'None' WITH YOUR CODE) ###\n",
        "    # initialize an instance of Trax's ReformerLM class\n",
        "    model = trax.models.reformer.ReformerLM( \n",
        "        # set vocab size\n",
        "        vocab_size = vocab_size,\n",
        "        # set number of layers\n",
        "        n_layers = n_layers,\n",
        "        # set mode\n",
        "        mode = mode,\n",
        "        # set attention type\n",
        "        attention_type = attention_type\n",
        "    )\n",
        "    \n",
        "    ### END CODE HERE ###\n",
        "    return model"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLoeOP4nY2Px"
      },
      "source": [
        "# **Training loop**\n",
        "Here a function `training_loop` that takes in my model and trains it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwAee10_Yylr"
      },
      "source": [
        "def training_loop(ReformerLM, train_gen, eval_gen, n_layers=2, output_dir = MODEL_DIR):\n",
        "    lr_schedule = trax.lr.warmup_and_rsqrt_decay(n_warmup_steps=1000, max_value=0.008)\n",
        "    \n",
        "    train_task = training.TrainTask(\n",
        "        labeled_data=train_gen,\n",
        "        loss_layer=tl.WeightedCategoryCrossEntropy(),\n",
        "        optimizer=trax.optimizers.Adam(0.01),\n",
        "        lr_schedule=lr_schedule,\n",
        "        n_steps_per_checkpoint=5\n",
        "    )\n",
        "    \n",
        "    eval_task = training.EvalTask(\n",
        "        labeled_data=eval_gen,\n",
        "        metrics=[tl.WeightedCategoryCrossEntropy(), tl.WeightedCategoryAccuracy()]\n",
        "    )\n",
        "    \n",
        "    loop = training.Loop(model=ReformerLM(n_layers=n_layers),\n",
        "                         tasks=[train_task],\n",
        "                         eval_tasks=[eval_task],\n",
        "                         output_dir=output_dir)\n",
        "    \n",
        "    return loop"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4U3e-ocY-Mi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2333cc42-5ca0-4a7c-aeb2-75924de03fe3"
      },
      "source": [
        "# training of a model or its loading from the file MODEL_DIR + '/model.pkl.gz'\n",
        "\n",
        "if LOAD_MODEL == False:\n",
        "  print(\"Creating a new model...\")\n",
        "  !rm -f $MODEL_DIR/model.pkl.gz\n",
        "  loop = training_loop(ReformerLM, train_stream, eval_stream, n_layers=N_LAYERS)\n",
        "else:\n",
        "  print(\"Loading a new model\")\n",
        "  loop = training_loop(ReformerLM, train_stream, eval_stream, n_layers=N_LAYERS)\n",
        "  loop.model.init_from_file(MODEL_DIR + '/model.pkl.gz')\n",
        "\n",
        "if TRAIN == True:\n",
        "  loop.run(TRAIN_STEPS)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating a new model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n",
            "/usr/local/lib/python3.7/dist-packages/jax/lib/xla_bridge.py:304: UserWarning: jax.host_id has been renamed to jax.process_index. This alias will eventually be removed; please update your code.\n",
            "  \"jax.host_id has been renamed to jax.process_index. This alias \"\n",
            "/usr/local/lib/python3.7/dist-packages/jax/lib/xla_bridge.py:317: UserWarning: jax.host_count has been renamed to jax.process_count. This alias will eventually be removed; please update your code.\n",
            "  \"jax.host_count has been renamed to jax.process_count. This alias \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Step      1: Total number of trainable weights: 96802640\n",
            "Step      1: Ran 1 train steps in 116.68 secs\n",
            "Step      1: train WeightedCategoryCrossEntropy |  10.84641933\n",
            "Step      1: eval  WeightedCategoryCrossEntropy |  10.84339046\n",
            "Step      1: eval      WeightedCategoryAccuracy |  0.00000000\n",
            "\n",
            "Step      5: Ran 4 train steps in 126.67 secs\n",
            "Step      5: train WeightedCategoryCrossEntropy |  10.78242779\n",
            "Step      5: eval  WeightedCategoryCrossEntropy |  10.62368202\n",
            "Step      5: eval      WeightedCategoryAccuracy |  0.01458080\n",
            "\n",
            "Step     10: Ran 5 train steps in 143.59 secs\n",
            "Step     10: train WeightedCategoryCrossEntropy |  10.46451664\n",
            "Step     10: eval  WeightedCategoryCrossEntropy |  10.21728039\n",
            "Step     10: eval      WeightedCategoryAccuracy |  0.05366269\n",
            "\n",
            "Step     15: Ran 5 train steps in 70.65 secs\n",
            "Step     15: train WeightedCategoryCrossEntropy |  9.98524952\n",
            "Step     15: eval  WeightedCategoryCrossEntropy |  9.57501507\n",
            "Step     15: eval      WeightedCategoryAccuracy |  0.04920914\n",
            "\n",
            "Step     20: Ran 5 train steps in 68.77 secs\n",
            "Step     20: train WeightedCategoryCrossEntropy |  9.27482700\n",
            "Step     20: eval  WeightedCategoryCrossEntropy |  8.77341747\n",
            "Step     20: eval      WeightedCategoryAccuracy |  0.04983660\n",
            "\n",
            "Step     25: Ran 5 train steps in 68.20 secs\n",
            "Step     25: train WeightedCategoryCrossEntropy |  8.37307739\n",
            "Step     25: eval  WeightedCategoryCrossEntropy |  7.76581430\n",
            "Step     25: eval      WeightedCategoryAccuracy |  0.04687500\n",
            "\n",
            "Step     30: Ran 5 train steps in 69.67 secs\n",
            "Step     30: train WeightedCategoryCrossEntropy |  7.25029516\n",
            "Step     30: eval  WeightedCategoryCrossEntropy |  6.62080956\n",
            "Step     30: eval      WeightedCategoryAccuracy |  0.05790297\n",
            "\n",
            "Step     35: Ran 5 train steps in 69.51 secs\n",
            "Step     35: train WeightedCategoryCrossEntropy |  6.14120722\n",
            "Step     35: eval  WeightedCategoryCrossEntropy |  5.64938021\n",
            "Step     35: eval      WeightedCategoryAccuracy |  0.05458090\n",
            "\n",
            "Step     40: Ran 5 train steps in 156.50 secs\n",
            "Step     40: train WeightedCategoryCrossEntropy |  5.48474789\n",
            "Step     40: eval  WeightedCategoryCrossEntropy |  5.32022667\n",
            "Step     40: eval      WeightedCategoryAccuracy |  0.04758923\n",
            "\n",
            "Step     45: Ran 5 train steps in 68.80 secs\n",
            "Step     45: train WeightedCategoryCrossEntropy |  5.27565527\n",
            "Step     45: eval  WeightedCategoryCrossEntropy |  5.17556858\n",
            "Step     45: eval      WeightedCategoryAccuracy |  0.06062670\n",
            "\n",
            "Step     50: Ran 5 train steps in 69.32 secs\n",
            "Step     50: train WeightedCategoryCrossEntropy |  5.26942778\n",
            "Step     50: eval  WeightedCategoryCrossEntropy |  5.18809319\n",
            "Step     50: eval      WeightedCategoryAccuracy |  0.05134788\n",
            "\n",
            "Step     55: Ran 5 train steps in 70.60 secs\n",
            "Step     55: train WeightedCategoryCrossEntropy |  5.26839733\n",
            "Step     55: eval  WeightedCategoryCrossEntropy |  5.28763962\n",
            "Step     55: eval      WeightedCategoryAccuracy |  0.04166667\n",
            "\n",
            "Step     60: Ran 5 train steps in 68.58 secs\n",
            "Step     60: train WeightedCategoryCrossEntropy |  5.23396587\n",
            "Step     60: eval  WeightedCategoryCrossEntropy |  5.37462187\n",
            "Step     60: eval      WeightedCategoryAccuracy |  0.04639175\n",
            "\n",
            "Step     65: Ran 5 train steps in 69.62 secs\n",
            "Step     65: train WeightedCategoryCrossEntropy |  5.22320604\n",
            "Step     65: eval  WeightedCategoryCrossEntropy |  5.26802540\n",
            "Step     65: eval      WeightedCategoryAccuracy |  0.04915103\n",
            "\n",
            "Step     70: Ran 5 train steps in 69.23 secs\n",
            "Step     70: train WeightedCategoryCrossEntropy |  5.22719908\n",
            "Step     70: eval  WeightedCategoryCrossEntropy |  5.15205574\n",
            "Step     70: eval      WeightedCategoryAccuracy |  0.06405934\n",
            "\n",
            "Step     75: Ran 5 train steps in 68.32 secs\n",
            "Step     75: train WeightedCategoryCrossEntropy |  5.30150700\n",
            "Step     75: eval  WeightedCategoryCrossEntropy |  5.21123314\n",
            "Step     75: eval      WeightedCategoryAccuracy |  0.05190539\n",
            "\n",
            "Step     80: Ran 5 train steps in 68.73 secs\n",
            "Step     80: train WeightedCategoryCrossEntropy |  5.26655674\n",
            "Step     80: eval  WeightedCategoryCrossEntropy |  5.16849995\n",
            "Step     80: eval      WeightedCategoryAccuracy |  0.05754951\n",
            "\n",
            "Step     85: Ran 5 train steps in 68.82 secs\n",
            "Step     85: train WeightedCategoryCrossEntropy |  5.23130560\n",
            "Step     85: eval  WeightedCategoryCrossEntropy |  5.20372725\n",
            "Step     85: eval      WeightedCategoryAccuracy |  0.04542505\n",
            "\n",
            "Step     90: Ran 5 train steps in 68.93 secs\n",
            "Step     90: train WeightedCategoryCrossEntropy |  5.32363033\n",
            "Step     90: eval  WeightedCategoryCrossEntropy |  5.11977243\n",
            "Step     90: eval      WeightedCategoryAccuracy |  0.06078431\n",
            "\n",
            "Step     95: Ran 5 train steps in 68.79 secs\n",
            "Step     95: train WeightedCategoryCrossEntropy |  5.21546221\n",
            "Step     95: eval  WeightedCategoryCrossEntropy |  5.29602385\n",
            "Step     95: eval      WeightedCategoryAccuracy |  0.04711347\n",
            "\n",
            "Step    100: Ran 5 train steps in 70.03 secs\n",
            "Step    100: train WeightedCategoryCrossEntropy |  5.22286606\n",
            "Step    100: eval  WeightedCategoryCrossEntropy |  5.24183178\n",
            "Step    100: eval      WeightedCategoryAccuracy |  0.04612428\n",
            "\n",
            "Step    105: Ran 5 train steps in 70.76 secs\n",
            "Step    105: train WeightedCategoryCrossEntropy |  5.20233870\n",
            "Step    105: eval  WeightedCategoryCrossEntropy |  5.07459450\n",
            "Step    105: eval      WeightedCategoryAccuracy |  0.06845514\n",
            "\n",
            "Step    110: Ran 5 train steps in 69.37 secs\n",
            "Step    110: train WeightedCategoryCrossEntropy |  5.23797226\n",
            "Step    110: eval  WeightedCategoryCrossEntropy |  5.21639681\n",
            "Step    110: eval      WeightedCategoryAccuracy |  0.06318840\n",
            "\n",
            "Step    115: Ran 5 train steps in 69.49 secs\n",
            "Step    115: train WeightedCategoryCrossEntropy |  5.21809959\n",
            "Step    115: eval  WeightedCategoryCrossEntropy |  5.28488159\n",
            "Step    115: eval      WeightedCategoryAccuracy |  0.06196944\n",
            "\n",
            "Step    120: Ran 5 train steps in 69.80 secs\n",
            "Step    120: train WeightedCategoryCrossEntropy |  5.13427114\n",
            "Step    120: eval  WeightedCategoryCrossEntropy |  5.30274534\n",
            "Step    120: eval      WeightedCategoryAccuracy |  0.06064356\n",
            "\n",
            "Step    125: Ran 5 train steps in 69.04 secs\n",
            "Step    125: train WeightedCategoryCrossEntropy |  5.18146515\n",
            "Step    125: eval  WeightedCategoryCrossEntropy |  5.31774950\n",
            "Step    125: eval      WeightedCategoryAccuracy |  0.04987981\n",
            "\n",
            "Step    130: Ran 5 train steps in 69.95 secs\n",
            "Step    130: train WeightedCategoryCrossEntropy |  5.18432522\n",
            "Step    130: eval  WeightedCategoryCrossEntropy |  5.12466764\n",
            "Step    130: eval      WeightedCategoryAccuracy |  0.05977497\n",
            "\n",
            "Step    135: Ran 5 train steps in 70.19 secs\n",
            "Step    135: train WeightedCategoryCrossEntropy |  5.19251490\n",
            "Step    135: eval  WeightedCategoryCrossEntropy |  5.21862698\n",
            "Step    135: eval      WeightedCategoryAccuracy |  0.05040650\n",
            "\n",
            "Step    140: Ran 5 train steps in 68.49 secs\n",
            "Step    140: train WeightedCategoryCrossEntropy |  5.15730286\n",
            "Step    140: eval  WeightedCategoryCrossEntropy |  5.28301620\n",
            "Step    140: eval      WeightedCategoryAccuracy |  0.04854369\n",
            "\n",
            "Step    145: Ran 5 train steps in 69.13 secs\n",
            "Step    145: train WeightedCategoryCrossEntropy |  5.23966932\n",
            "Step    145: eval  WeightedCategoryCrossEntropy |  5.20958853\n",
            "Step    145: eval      WeightedCategoryAccuracy |  0.05344418\n",
            "\n",
            "Step    150: Ran 5 train steps in 69.19 secs\n",
            "Step    150: train WeightedCategoryCrossEntropy |  5.23053074\n",
            "Step    150: eval  WeightedCategoryCrossEntropy |  5.17637539\n",
            "Step    150: eval      WeightedCategoryAccuracy |  0.05793991\n",
            "\n",
            "Step    155: Ran 5 train steps in 68.43 secs\n",
            "Step    155: train WeightedCategoryCrossEntropy |  5.22578287\n",
            "Step    155: eval  WeightedCategoryCrossEntropy |  5.32000065\n",
            "Step    155: eval      WeightedCategoryAccuracy |  0.03428094\n",
            "\n",
            "Step    160: Ran 5 train steps in 69.92 secs\n",
            "Step    160: train WeightedCategoryCrossEntropy |  5.24206686\n",
            "Step    160: eval  WeightedCategoryCrossEntropy |  5.18671703\n",
            "Step    160: eval      WeightedCategoryAccuracy |  0.06227631\n",
            "\n",
            "Step    165: Ran 5 train steps in 69.13 secs\n",
            "Step    165: train WeightedCategoryCrossEntropy |  5.26165104\n",
            "Step    165: eval  WeightedCategoryCrossEntropy |  5.23266792\n",
            "Step    165: eval      WeightedCategoryAccuracy |  0.06241234\n",
            "\n",
            "Step    170: Ran 5 train steps in 68.94 secs\n",
            "Step    170: train WeightedCategoryCrossEntropy |  5.25231838\n",
            "Step    170: eval  WeightedCategoryCrossEntropy |  5.23358154\n",
            "Step    170: eval      WeightedCategoryAccuracy |  0.05902540\n",
            "\n",
            "Step    175: Ran 5 train steps in 69.29 secs\n",
            "Step    175: train WeightedCategoryCrossEntropy |  5.17910862\n",
            "Step    175: eval  WeightedCategoryCrossEntropy |  5.12731457\n",
            "Step    175: eval      WeightedCategoryAccuracy |  0.07364976\n",
            "\n",
            "Step    180: Ran 5 train steps in 69.61 secs\n",
            "Step    180: train WeightedCategoryCrossEntropy |  5.25508785\n",
            "Step    180: eval  WeightedCategoryCrossEntropy |  5.19311857\n",
            "Step    180: eval      WeightedCategoryAccuracy |  0.08557047\n",
            "\n",
            "Step    185: Ran 5 train steps in 70.65 secs\n",
            "Step    185: train WeightedCategoryCrossEntropy |  5.15871382\n",
            "Step    185: eval  WeightedCategoryCrossEntropy |  5.15350294\n",
            "Step    185: eval      WeightedCategoryAccuracy |  0.11287478\n",
            "\n",
            "Step    190: Ran 5 train steps in 69.39 secs\n",
            "Step    190: train WeightedCategoryCrossEntropy |  5.19953012\n",
            "Step    190: eval  WeightedCategoryCrossEntropy |  5.30775785\n",
            "Step    190: eval      WeightedCategoryAccuracy |  0.06173594\n",
            "\n",
            "Step    195: Ran 5 train steps in 69.07 secs\n",
            "Step    195: train WeightedCategoryCrossEntropy |  5.20588446\n",
            "Step    195: eval  WeightedCategoryCrossEntropy |  5.36119223\n",
            "Step    195: eval      WeightedCategoryAccuracy |  0.08160443\n",
            "\n",
            "Step    200: Ran 5 train steps in 68.83 secs\n",
            "Step    200: train WeightedCategoryCrossEntropy |  4.99223804\n",
            "Step    200: eval  WeightedCategoryCrossEntropy |  5.30526257\n",
            "Step    200: eval      WeightedCategoryAccuracy |  0.05376344\n",
            "\n",
            "Step    205: Ran 5 train steps in 69.52 secs\n",
            "Step    205: train WeightedCategoryCrossEntropy |  5.05060101\n",
            "Step    205: eval  WeightedCategoryCrossEntropy |  4.71791220\n",
            "Step    205: eval      WeightedCategoryAccuracy |  0.12383613\n",
            "\n",
            "Step    210: Ran 5 train steps in 69.39 secs\n",
            "Step    210: train WeightedCategoryCrossEntropy |  4.84150028\n",
            "Step    210: eval  WeightedCategoryCrossEntropy |  4.70115948\n",
            "Step    210: eval      WeightedCategoryAccuracy |  0.12927191\n",
            "\n",
            "Step    215: Ran 5 train steps in 68.43 secs\n",
            "Step    215: train WeightedCategoryCrossEntropy |  4.69927406\n",
            "Step    215: eval  WeightedCategoryCrossEntropy |  4.64790773\n",
            "Step    215: eval      WeightedCategoryAccuracy |  0.13345984\n",
            "\n",
            "Step    220: Ran 5 train steps in 68.74 secs\n",
            "Step    220: train WeightedCategoryCrossEntropy |  4.74977827\n",
            "Step    220: eval  WeightedCategoryCrossEntropy |  4.50109673\n",
            "Step    220: eval      WeightedCategoryAccuracy |  0.13098465\n",
            "\n",
            "Step    225: Ran 5 train steps in 69.71 secs\n",
            "Step    225: train WeightedCategoryCrossEntropy |  4.54772091\n",
            "Step    225: eval  WeightedCategoryCrossEntropy |  4.49741936\n",
            "Step    225: eval      WeightedCategoryAccuracy |  0.16207951\n",
            "\n",
            "Step    230: Ran 5 train steps in 73.95 secs\n",
            "Step    230: train WeightedCategoryCrossEntropy |  4.53557444\n",
            "Step    230: eval  WeightedCategoryCrossEntropy |  4.34571934\n",
            "Step    230: eval      WeightedCategoryAccuracy |  0.14338575\n",
            "\n",
            "Step    235: Ran 5 train steps in 68.69 secs\n",
            "Step    235: train WeightedCategoryCrossEntropy |  4.49918079\n",
            "Step    235: eval  WeightedCategoryCrossEntropy |  4.33595896\n",
            "Step    235: eval      WeightedCategoryAccuracy |  0.16666667\n",
            "\n",
            "Step    240: Ran 5 train steps in 68.90 secs\n",
            "Step    240: train WeightedCategoryCrossEntropy |  4.35260534\n",
            "Step    240: eval  WeightedCategoryCrossEntropy |  4.40339470\n",
            "Step    240: eval      WeightedCategoryAccuracy |  0.15775917\n",
            "\n",
            "Step    245: Ran 5 train steps in 68.90 secs\n",
            "Step    245: train WeightedCategoryCrossEntropy |  4.41465712\n",
            "Step    245: eval  WeightedCategoryCrossEntropy |  4.70376873\n",
            "Step    245: eval      WeightedCategoryAccuracy |  0.17721519\n",
            "\n",
            "Step    250: Ran 5 train steps in 69.06 secs\n",
            "Step    250: train WeightedCategoryCrossEntropy |  4.25764465\n",
            "Step    250: eval  WeightedCategoryCrossEntropy |  4.38657951\n",
            "Step    250: eval      WeightedCategoryAccuracy |  0.18037319\n",
            "\n",
            "Step    255: Ran 5 train steps in 69.67 secs\n",
            "Step    255: train WeightedCategoryCrossEntropy |  4.29479313\n",
            "Step    255: eval  WeightedCategoryCrossEntropy |  4.21768284\n",
            "Step    255: eval      WeightedCategoryAccuracy |  0.20231660\n",
            "\n",
            "Step    260: Ran 5 train steps in 69.31 secs\n",
            "Step    260: train WeightedCategoryCrossEntropy |  4.18078995\n",
            "Step    260: eval  WeightedCategoryCrossEntropy |  4.27753401\n",
            "Step    260: eval      WeightedCategoryAccuracy |  0.18701482\n",
            "\n",
            "Step    265: Ran 5 train steps in 68.65 secs\n",
            "Step    265: train WeightedCategoryCrossEntropy |  4.31586933\n",
            "Step    265: eval  WeightedCategoryCrossEntropy |  4.26557589\n",
            "Step    265: eval      WeightedCategoryAccuracy |  0.18825781\n",
            "\n",
            "Step    270: Ran 5 train steps in 69.69 secs\n",
            "Step    270: train WeightedCategoryCrossEntropy |  4.23080492\n",
            "Step    270: eval  WeightedCategoryCrossEntropy |  4.30298948\n",
            "Step    270: eval      WeightedCategoryAccuracy |  0.20898877\n",
            "\n",
            "Step    275: Ran 5 train steps in 69.07 secs\n",
            "Step    275: train WeightedCategoryCrossEntropy |  4.17756891\n",
            "Step    275: eval  WeightedCategoryCrossEntropy |  4.10552597\n",
            "Step    275: eval      WeightedCategoryAccuracy |  0.21262209\n",
            "\n",
            "Step    280: Ran 5 train steps in 68.29 secs\n",
            "Step    280: train WeightedCategoryCrossEntropy |  4.15933847\n",
            "Step    280: eval  WeightedCategoryCrossEntropy |  4.23015356\n",
            "Step    280: eval      WeightedCategoryAccuracy |  0.22388060\n",
            "\n",
            "Step    285: Ran 5 train steps in 71.42 secs\n",
            "Step    285: train WeightedCategoryCrossEntropy |  4.13816643\n",
            "Step    285: eval  WeightedCategoryCrossEntropy |  4.26628923\n",
            "Step    285: eval      WeightedCategoryAccuracy |  0.20334262\n",
            "\n",
            "Step    290: Ran 5 train steps in 71.36 secs\n",
            "Step    290: train WeightedCategoryCrossEntropy |  4.09401560\n",
            "Step    290: eval  WeightedCategoryCrossEntropy |  4.17412806\n",
            "Step    290: eval      WeightedCategoryAccuracy |  0.23025516\n",
            "\n",
            "Step    295: Ran 5 train steps in 71.43 secs\n",
            "Step    295: train WeightedCategoryCrossEntropy |  4.00574207\n",
            "Step    295: eval  WeightedCategoryCrossEntropy |  4.06602192\n",
            "Step    295: eval      WeightedCategoryAccuracy |  0.23693803\n",
            "\n",
            "Step    300: Ran 5 train steps in 70.10 secs\n",
            "Step    300: train WeightedCategoryCrossEntropy |  4.00835800\n",
            "Step    300: eval  WeightedCategoryCrossEntropy |  3.92086077\n",
            "Step    300: eval      WeightedCategoryAccuracy |  0.23751095\n",
            "\n",
            "Step    305: Ran 5 train steps in 69.68 secs\n",
            "Step    305: train WeightedCategoryCrossEntropy |  3.94139338\n",
            "Step    305: eval  WeightedCategoryCrossEntropy |  4.20398283\n",
            "Step    305: eval      WeightedCategoryAccuracy |  0.21951219\n",
            "\n",
            "Step    310: Ran 5 train steps in 72.20 secs\n",
            "Step    310: train WeightedCategoryCrossEntropy |  3.98210669\n",
            "Step    310: eval  WeightedCategoryCrossEntropy |  4.04991436\n",
            "Step    310: eval      WeightedCategoryAccuracy |  0.24919355\n",
            "\n",
            "Step    315: Ran 5 train steps in 69.44 secs\n",
            "Step    315: train WeightedCategoryCrossEntropy |  3.85931921\n",
            "Step    315: eval  WeightedCategoryCrossEntropy |  3.91686130\n",
            "Step    315: eval      WeightedCategoryAccuracy |  0.23996852\n",
            "\n",
            "Step    320: Ran 5 train steps in 70.28 secs\n",
            "Step    320: train WeightedCategoryCrossEntropy |  3.93199229\n",
            "Step    320: eval  WeightedCategoryCrossEntropy |  4.08350801\n",
            "Step    320: eval      WeightedCategoryAccuracy |  0.24181548\n",
            "\n",
            "Step    325: Ran 5 train steps in 70.40 secs\n",
            "Step    325: train WeightedCategoryCrossEntropy |  3.93810916\n",
            "Step    325: eval  WeightedCategoryCrossEntropy |  4.09390688\n",
            "Step    325: eval      WeightedCategoryAccuracy |  0.25248510\n",
            "\n",
            "Step    330: Ran 5 train steps in 69.55 secs\n",
            "Step    330: train WeightedCategoryCrossEntropy |  3.92985487\n",
            "Step    330: eval  WeightedCategoryCrossEntropy |  3.90986896\n",
            "Step    330: eval      WeightedCategoryAccuracy |  0.24219409\n",
            "\n",
            "Step    335: Ran 5 train steps in 69.12 secs\n",
            "Step    335: train WeightedCategoryCrossEntropy |  3.89931607\n",
            "Step    335: eval  WeightedCategoryCrossEntropy |  3.85862851\n",
            "Step    335: eval      WeightedCategoryAccuracy |  0.26857531\n",
            "\n",
            "Step    340: Ran 5 train steps in 68.70 secs\n",
            "Step    340: train WeightedCategoryCrossEntropy |  3.93806529\n",
            "Step    340: eval  WeightedCategoryCrossEntropy |  3.97850180\n",
            "Step    340: eval      WeightedCategoryAccuracy |  0.23331130\n",
            "\n",
            "Step    345: Ran 5 train steps in 69.93 secs\n",
            "Step    345: train WeightedCategoryCrossEntropy |  3.73649096\n",
            "Step    345: eval  WeightedCategoryCrossEntropy |  3.79102087\n",
            "Step    345: eval      WeightedCategoryAccuracy |  0.27112675\n",
            "\n",
            "Step    350: Ran 5 train steps in 70.74 secs\n",
            "Step    350: train WeightedCategoryCrossEntropy |  3.75818872\n",
            "Step    350: eval  WeightedCategoryCrossEntropy |  3.81839490\n",
            "Step    350: eval      WeightedCategoryAccuracy |  0.26184538\n",
            "\n",
            "Step    355: Ran 5 train steps in 69.80 secs\n",
            "Step    355: train WeightedCategoryCrossEntropy |  3.75295877\n",
            "Step    355: eval  WeightedCategoryCrossEntropy |  3.56683397\n",
            "Step    355: eval      WeightedCategoryAccuracy |  0.28411216\n",
            "\n",
            "Step    360: Ran 5 train steps in 69.34 secs\n",
            "Step    360: train WeightedCategoryCrossEntropy |  3.73259306\n",
            "Step    360: eval  WeightedCategoryCrossEntropy |  3.84621835\n",
            "Step    360: eval      WeightedCategoryAccuracy |  0.27355427\n",
            "\n",
            "Step    365: Ran 5 train steps in 69.67 secs\n",
            "Step    365: train WeightedCategoryCrossEntropy |  3.73082805\n",
            "Step    365: eval  WeightedCategoryCrossEntropy |  3.89213896\n",
            "Step    365: eval      WeightedCategoryAccuracy |  0.26993465\n",
            "\n",
            "Step    370: Ran 5 train steps in 68.94 secs\n",
            "Step    370: train WeightedCategoryCrossEntropy |  3.77988434\n",
            "Step    370: eval  WeightedCategoryCrossEntropy |  3.67441750\n",
            "Step    370: eval      WeightedCategoryAccuracy |  0.29553264\n",
            "\n",
            "Step    375: Ran 5 train steps in 70.08 secs\n",
            "Step    375: train WeightedCategoryCrossEntropy |  3.69139862\n",
            "Step    375: eval  WeightedCategoryCrossEntropy |  3.70623684\n",
            "Step    375: eval      WeightedCategoryAccuracy |  0.27826086\n",
            "\n",
            "Step    380: Ran 5 train steps in 70.58 secs\n",
            "Step    380: train WeightedCategoryCrossEntropy |  3.62593222\n",
            "Step    380: eval  WeightedCategoryCrossEntropy |  3.65621805\n",
            "Step    380: eval      WeightedCategoryAccuracy |  0.28582802\n",
            "\n",
            "Step    385: Ran 5 train steps in 70.00 secs\n",
            "Step    385: train WeightedCategoryCrossEntropy |  3.69236636\n",
            "Step    385: eval  WeightedCategoryCrossEntropy |  3.67337322\n",
            "Step    385: eval      WeightedCategoryAccuracy |  0.27659574\n",
            "\n",
            "Step    390: Ran 5 train steps in 69.14 secs\n",
            "Step    390: train WeightedCategoryCrossEntropy |  3.66827393\n",
            "Step    390: eval  WeightedCategoryCrossEntropy |  3.72961307\n",
            "Step    390: eval      WeightedCategoryAccuracy |  0.27900738\n",
            "\n",
            "Step    395: Ran 5 train steps in 70.27 secs\n",
            "Step    395: train WeightedCategoryCrossEntropy |  3.70043683\n",
            "Step    395: eval  WeightedCategoryCrossEntropy |  3.66638303\n",
            "Step    395: eval      WeightedCategoryAccuracy |  0.28355128\n",
            "\n",
            "Step    400: Ran 5 train steps in 69.20 secs\n",
            "Step    400: train WeightedCategoryCrossEntropy |  3.54810214\n",
            "Step    400: eval  WeightedCategoryCrossEntropy |  3.48642230\n",
            "Step    400: eval      WeightedCategoryAccuracy |  0.31497976\n",
            "\n",
            "Step    405: Ran 5 train steps in 68.73 secs\n",
            "Step    405: train WeightedCategoryCrossEntropy |  3.67861438\n",
            "Step    405: eval  WeightedCategoryCrossEntropy |  3.61162853\n",
            "Step    405: eval      WeightedCategoryAccuracy |  0.28627709\n",
            "\n",
            "Step    410: Ran 5 train steps in 69.41 secs\n",
            "Step    410: train WeightedCategoryCrossEntropy |  3.62309384\n",
            "Step    410: eval  WeightedCategoryCrossEntropy |  3.53913403\n",
            "Step    410: eval      WeightedCategoryAccuracy |  0.30239898\n",
            "\n",
            "Step    415: Ran 5 train steps in 69.88 secs\n",
            "Step    415: train WeightedCategoryCrossEntropy |  3.62141418\n",
            "Step    415: eval  WeightedCategoryCrossEntropy |  3.33381271\n",
            "Step    415: eval      WeightedCategoryAccuracy |  0.30584851\n",
            "\n",
            "Step    420: Ran 5 train steps in 70.22 secs\n",
            "Step    420: train WeightedCategoryCrossEntropy |  3.53899956\n",
            "Step    420: eval  WeightedCategoryCrossEntropy |  3.58608508\n",
            "Step    420: eval      WeightedCategoryAccuracy |  0.29596978\n",
            "\n",
            "Step    425: Ran 5 train steps in 69.75 secs\n",
            "Step    425: train WeightedCategoryCrossEntropy |  3.65441895\n",
            "Step    425: eval  WeightedCategoryCrossEntropy |  3.62006760\n",
            "Step    425: eval      WeightedCategoryAccuracy |  0.28460544\n",
            "\n",
            "Step    430: Ran 5 train steps in 68.83 secs\n",
            "Step    430: train WeightedCategoryCrossEntropy |  3.54431152\n",
            "Step    430: eval  WeightedCategoryCrossEntropy |  3.79962921\n",
            "Step    430: eval      WeightedCategoryAccuracy |  0.28259233\n",
            "\n",
            "Step    435: Ran 5 train steps in 69.36 secs\n",
            "Step    435: train WeightedCategoryCrossEntropy |  3.56175303\n",
            "Step    435: eval  WeightedCategoryCrossEntropy |  3.46933270\n",
            "Step    435: eval      WeightedCategoryAccuracy |  0.31021556\n",
            "\n",
            "Step    440: Ran 5 train steps in 68.63 secs\n",
            "Step    440: train WeightedCategoryCrossEntropy |  3.59278369\n",
            "Step    440: eval  WeightedCategoryCrossEntropy |  3.53000498\n",
            "Step    440: eval      WeightedCategoryAccuracy |  0.27902621\n",
            "\n",
            "Step    445: Ran 5 train steps in 69.24 secs\n",
            "Step    445: train WeightedCategoryCrossEntropy |  3.55424690\n",
            "Step    445: eval  WeightedCategoryCrossEntropy |  3.74696589\n",
            "Step    445: eval      WeightedCategoryAccuracy |  0.31039757\n",
            "\n",
            "Step    450: Ran 5 train steps in 69.38 secs\n",
            "Step    450: train WeightedCategoryCrossEntropy |  3.55122685\n",
            "Step    450: eval  WeightedCategoryCrossEntropy |  3.37250805\n",
            "Step    450: eval      WeightedCategoryAccuracy |  0.32762030\n",
            "\n",
            "Step    455: Ran 5 train steps in 70.41 secs\n",
            "Step    455: train WeightedCategoryCrossEntropy |  3.52287340\n",
            "Step    455: eval  WeightedCategoryCrossEntropy |  3.63266802\n",
            "Step    455: eval      WeightedCategoryAccuracy |  0.30577427\n",
            "\n",
            "Step    460: Ran 5 train steps in 68.68 secs\n",
            "Step    460: train WeightedCategoryCrossEntropy |  3.46744466\n",
            "Step    460: eval  WeightedCategoryCrossEntropy |  3.39928174\n",
            "Step    460: eval      WeightedCategoryAccuracy |  0.31238216\n",
            "\n",
            "Step    465: Ran 5 train steps in 69.76 secs\n",
            "Step    465: train WeightedCategoryCrossEntropy |  3.46665263\n",
            "Step    465: eval  WeightedCategoryCrossEntropy |  3.33125520\n",
            "Step    465: eval      WeightedCategoryAccuracy |  0.32545453\n",
            "\n",
            "Step    470: Ran 5 train steps in 68.62 secs\n",
            "Step    470: train WeightedCategoryCrossEntropy |  3.49113727\n",
            "Step    470: eval  WeightedCategoryCrossEntropy |  3.42849684\n",
            "Step    470: eval      WeightedCategoryAccuracy |  0.30387685\n",
            "\n",
            "Step    475: Ran 5 train steps in 70.08 secs\n",
            "Step    475: train WeightedCategoryCrossEntropy |  3.45358014\n",
            "Step    475: eval  WeightedCategoryCrossEntropy |  3.53394079\n",
            "Step    475: eval      WeightedCategoryAccuracy |  0.29967639\n",
            "\n",
            "Step    480: Ran 5 train steps in 69.66 secs\n",
            "Step    480: train WeightedCategoryCrossEntropy |  3.50720096\n",
            "Step    480: eval  WeightedCategoryCrossEntropy |  3.39442420\n",
            "Step    480: eval      WeightedCategoryAccuracy |  0.31083202\n",
            "\n",
            "Step    485: Ran 5 train steps in 70.27 secs\n",
            "Step    485: train WeightedCategoryCrossEntropy |  3.41933441\n",
            "Step    485: eval  WeightedCategoryCrossEntropy |  3.30076265\n",
            "Step    485: eval      WeightedCategoryAccuracy |  0.32184616\n",
            "\n",
            "Step    490: Ran 5 train steps in 68.35 secs\n",
            "Step    490: train WeightedCategoryCrossEntropy |  3.42071581\n",
            "Step    490: eval  WeightedCategoryCrossEntropy |  3.41402912\n",
            "Step    490: eval      WeightedCategoryAccuracy |  0.31171021\n",
            "\n",
            "Step    495: Ran 5 train steps in 69.05 secs\n",
            "Step    495: train WeightedCategoryCrossEntropy |  3.37016535\n",
            "Step    495: eval  WeightedCategoryCrossEntropy |  3.37496352\n",
            "Step    495: eval      WeightedCategoryAccuracy |  0.31096849\n",
            "\n",
            "Step    500: Ran 5 train steps in 69.14 secs\n",
            "Step    500: train WeightedCategoryCrossEntropy |  3.47436333\n",
            "Step    500: eval  WeightedCategoryCrossEntropy |  3.38958311\n",
            "Step    500: eval      WeightedCategoryAccuracy |  0.31684700\n",
            "\n",
            "Step    505: Ran 5 train steps in 68.57 secs\n",
            "Step    505: train WeightedCategoryCrossEntropy |  3.43736982\n",
            "Step    505: eval  WeightedCategoryCrossEntropy |  3.32305121\n",
            "Step    505: eval      WeightedCategoryAccuracy |  0.32666305\n",
            "\n",
            "Step    510: Ran 5 train steps in 68.19 secs\n",
            "Step    510: train WeightedCategoryCrossEntropy |  3.45058322\n",
            "Step    510: eval  WeightedCategoryCrossEntropy |  3.47925162\n",
            "Step    510: eval      WeightedCategoryAccuracy |  0.30362320\n",
            "\n",
            "Step    515: Ran 5 train steps in 68.34 secs\n",
            "Step    515: train WeightedCategoryCrossEntropy |  3.39701891\n",
            "Step    515: eval  WeightedCategoryCrossEntropy |  3.49094224\n",
            "Step    515: eval      WeightedCategoryAccuracy |  0.32350719\n",
            "\n",
            "Step    520: Ran 5 train steps in 69.45 secs\n",
            "Step    520: train WeightedCategoryCrossEntropy |  3.39406013\n",
            "Step    520: eval  WeightedCategoryCrossEntropy |  3.33818173\n",
            "Step    520: eval      WeightedCategoryAccuracy |  0.32651901\n",
            "\n",
            "Step    525: Ran 5 train steps in 69.38 secs\n",
            "Step    525: train WeightedCategoryCrossEntropy |  3.48222876\n",
            "Step    525: eval  WeightedCategoryCrossEntropy |  3.37582779\n",
            "Step    525: eval      WeightedCategoryAccuracy |  0.33098590\n",
            "\n",
            "Step    530: Ran 5 train steps in 69.09 secs\n",
            "Step    530: train WeightedCategoryCrossEntropy |  3.41006398\n",
            "Step    530: eval  WeightedCategoryCrossEntropy |  3.41329908\n",
            "Step    530: eval      WeightedCategoryAccuracy |  0.32088682\n",
            "\n",
            "Step    535: Ran 5 train steps in 69.99 secs\n",
            "Step    535: train WeightedCategoryCrossEntropy |  3.38288426\n",
            "Step    535: eval  WeightedCategoryCrossEntropy |  3.49340391\n",
            "Step    535: eval      WeightedCategoryAccuracy |  0.32639468\n",
            "\n",
            "Step    540: Ran 5 train steps in 70.30 secs\n",
            "Step    540: train WeightedCategoryCrossEntropy |  3.34443212\n",
            "Step    540: eval  WeightedCategoryCrossEntropy |  3.31363821\n",
            "Step    540: eval      WeightedCategoryAccuracy |  0.33942160\n",
            "\n",
            "Step    545: Ran 5 train steps in 69.82 secs\n",
            "Step    545: train WeightedCategoryCrossEntropy |  3.39012861\n",
            "Step    545: eval  WeightedCategoryCrossEntropy |  3.39283323\n",
            "Step    545: eval      WeightedCategoryAccuracy |  0.31604278\n",
            "\n",
            "Step    550: Ran 5 train steps in 73.42 secs\n",
            "Step    550: train WeightedCategoryCrossEntropy |  3.35264587\n",
            "Step    550: eval  WeightedCategoryCrossEntropy |  3.26347351\n",
            "Step    550: eval      WeightedCategoryAccuracy |  0.33358547\n",
            "\n",
            "Step    555: Ran 5 train steps in 69.79 secs\n",
            "Step    555: train WeightedCategoryCrossEntropy |  3.36196661\n",
            "Step    555: eval  WeightedCategoryCrossEntropy |  3.28112888\n",
            "Step    555: eval      WeightedCategoryAccuracy |  0.33700642\n",
            "\n",
            "Step    560: Ran 5 train steps in 71.39 secs\n",
            "Step    560: train WeightedCategoryCrossEntropy |  3.37522960\n",
            "Step    560: eval  WeightedCategoryCrossEntropy |  3.31896734\n",
            "Step    560: eval      WeightedCategoryAccuracy |  0.33238366\n",
            "\n",
            "Step    565: Ran 5 train steps in 69.30 secs\n",
            "Step    565: train WeightedCategoryCrossEntropy |  3.37456965\n",
            "Step    565: eval  WeightedCategoryCrossEntropy |  3.30187583\n",
            "Step    565: eval      WeightedCategoryAccuracy |  0.32980132\n",
            "\n",
            "Step    570: Ran 5 train steps in 70.90 secs\n",
            "Step    570: train WeightedCategoryCrossEntropy |  3.39823723\n",
            "Step    570: eval  WeightedCategoryCrossEntropy |  3.44626713\n",
            "Step    570: eval      WeightedCategoryAccuracy |  0.32584271\n",
            "\n",
            "Step    575: Ran 5 train steps in 73.09 secs\n",
            "Step    575: train WeightedCategoryCrossEntropy |  3.40689087\n",
            "Step    575: eval  WeightedCategoryCrossEntropy |  3.33062959\n",
            "Step    575: eval      WeightedCategoryAccuracy |  0.33649635\n",
            "\n",
            "Step    580: Ran 5 train steps in 71.56 secs\n",
            "Step    580: train WeightedCategoryCrossEntropy |  3.45484471\n",
            "Step    580: eval  WeightedCategoryCrossEntropy |  3.18073058\n",
            "Step    580: eval      WeightedCategoryAccuracy |  0.36849409\n",
            "\n",
            "Step    585: Ran 5 train steps in 70.07 secs\n",
            "Step    585: train WeightedCategoryCrossEntropy |  3.32815027\n",
            "Step    585: eval  WeightedCategoryCrossEntropy |  3.21383834\n",
            "Step    585: eval      WeightedCategoryAccuracy |  0.34366196\n",
            "\n",
            "Step    590: Ran 5 train steps in 70.51 secs\n",
            "Step    590: train WeightedCategoryCrossEntropy |  3.33372045\n",
            "Step    590: eval  WeightedCategoryCrossEntropy |  3.42016506\n",
            "Step    590: eval      WeightedCategoryAccuracy |  0.31845966\n",
            "\n",
            "Step    595: Ran 5 train steps in 69.66 secs\n",
            "Step    595: train WeightedCategoryCrossEntropy |  3.34737086\n",
            "Step    595: eval  WeightedCategoryCrossEntropy |  3.28184533\n",
            "Step    595: eval      WeightedCategoryAccuracy |  0.32768363\n",
            "\n",
            "Step    600: Ran 5 train steps in 69.77 secs\n",
            "Step    600: train WeightedCategoryCrossEntropy |  3.35091853\n",
            "Step    600: eval  WeightedCategoryCrossEntropy |  3.17653942\n",
            "Step    600: eval      WeightedCategoryAccuracy |  0.34515819\n",
            "\n",
            "Step    605: Ran 5 train steps in 69.15 secs\n",
            "Step    605: train WeightedCategoryCrossEntropy |  3.35218859\n",
            "Step    605: eval  WeightedCategoryCrossEntropy |  3.48882294\n",
            "Step    605: eval      WeightedCategoryAccuracy |  0.33101851\n",
            "\n",
            "Step    610: Ran 5 train steps in 68.43 secs\n",
            "Step    610: train WeightedCategoryCrossEntropy |  3.31743360\n",
            "Step    610: eval  WeightedCategoryCrossEntropy |  3.39010119\n",
            "Step    610: eval      WeightedCategoryAccuracy |  0.31559139\n",
            "\n",
            "Step    615: Ran 5 train steps in 69.46 secs\n",
            "Step    615: train WeightedCategoryCrossEntropy |  3.39427185\n",
            "Step    615: eval  WeightedCategoryCrossEntropy |  3.49977970\n",
            "Step    615: eval      WeightedCategoryAccuracy |  0.29836830\n",
            "\n",
            "Step    620: Ran 5 train steps in 69.49 secs\n",
            "Step    620: train WeightedCategoryCrossEntropy |  3.35294032\n",
            "Step    620: eval  WeightedCategoryCrossEntropy |  3.62327480\n",
            "Step    620: eval      WeightedCategoryAccuracy |  0.34705159\n",
            "\n",
            "Step    625: Ran 5 train steps in 68.98 secs\n",
            "Step    625: train WeightedCategoryCrossEntropy |  3.35668135\n",
            "Step    625: eval  WeightedCategoryCrossEntropy |  3.14665627\n",
            "Step    625: eval      WeightedCategoryAccuracy |  0.34751773\n",
            "\n",
            "Step    630: Ran 5 train steps in 68.20 secs\n",
            "Step    630: train WeightedCategoryCrossEntropy |  3.28865552\n",
            "Step    630: eval  WeightedCategoryCrossEntropy |  3.41380811\n",
            "Step    630: eval      WeightedCategoryAccuracy |  0.32488006\n",
            "\n",
            "Step    635: Ran 5 train steps in 70.01 secs\n",
            "Step    635: train WeightedCategoryCrossEntropy |  3.24478793\n",
            "Step    635: eval  WeightedCategoryCrossEntropy |  3.32320690\n",
            "Step    635: eval      WeightedCategoryAccuracy |  0.32041728\n",
            "\n",
            "Step    640: Ran 5 train steps in 68.95 secs\n",
            "Step    640: train WeightedCategoryCrossEntropy |  3.27065158\n",
            "Step    640: eval  WeightedCategoryCrossEntropy |  3.41240239\n",
            "Step    640: eval      WeightedCategoryAccuracy |  0.32847342\n",
            "\n",
            "Step    645: Ran 5 train steps in 68.54 secs\n",
            "Step    645: train WeightedCategoryCrossEntropy |  3.33838415\n",
            "Step    645: eval  WeightedCategoryCrossEntropy |  3.32745910\n",
            "Step    645: eval      WeightedCategoryAccuracy |  0.33006307\n",
            "\n",
            "Step    650: Ran 5 train steps in 70.08 secs\n",
            "Step    650: train WeightedCategoryCrossEntropy |  3.37404490\n",
            "Step    650: eval  WeightedCategoryCrossEntropy |  3.41038609\n",
            "Step    650: eval      WeightedCategoryAccuracy |  0.32395211\n",
            "\n",
            "Step    655: Ran 5 train steps in 68.46 secs\n",
            "Step    655: train WeightedCategoryCrossEntropy |  3.41798139\n",
            "Step    655: eval  WeightedCategoryCrossEntropy |  3.42066956\n",
            "Step    655: eval      WeightedCategoryAccuracy |  0.30409837\n",
            "\n",
            "Step    660: Ran 5 train steps in 68.37 secs\n",
            "Step    660: train WeightedCategoryCrossEntropy |  3.33934665\n",
            "Step    660: eval  WeightedCategoryCrossEntropy |  3.35457397\n",
            "Step    660: eval      WeightedCategoryAccuracy |  0.32396251\n",
            "\n",
            "Step    665: Ran 5 train steps in 68.58 secs\n",
            "Step    665: train WeightedCategoryCrossEntropy |  3.34515691\n",
            "Step    665: eval  WeightedCategoryCrossEntropy |  3.36682487\n",
            "Step    665: eval      WeightedCategoryAccuracy |  0.33775297\n",
            "\n",
            "Step    670: Ran 5 train steps in 70.54 secs\n",
            "Step    670: train WeightedCategoryCrossEntropy |  3.40775752\n",
            "Step    670: eval  WeightedCategoryCrossEntropy |  3.37369299\n",
            "Step    670: eval      WeightedCategoryAccuracy |  0.33308661\n",
            "\n",
            "Step    675: Ran 5 train steps in 70.33 secs\n",
            "Step    675: train WeightedCategoryCrossEntropy |  3.25405169\n",
            "Step    675: eval  WeightedCategoryCrossEntropy |  3.26182103\n",
            "Step    675: eval      WeightedCategoryAccuracy |  0.33582553\n",
            "\n",
            "Step    680: Ran 5 train steps in 71.39 secs\n",
            "Step    680: train WeightedCategoryCrossEntropy |  3.31687045\n",
            "Step    680: eval  WeightedCategoryCrossEntropy |  3.31103206\n",
            "Step    680: eval      WeightedCategoryAccuracy |  0.33093524\n",
            "\n",
            "Step    685: Ran 5 train steps in 70.63 secs\n",
            "Step    685: train WeightedCategoryCrossEntropy |  3.31255484\n",
            "Step    685: eval  WeightedCategoryCrossEntropy |  3.35105252\n",
            "Step    685: eval      WeightedCategoryAccuracy |  0.33353257\n",
            "\n",
            "Step    690: Ran 5 train steps in 70.88 secs\n",
            "Step    690: train WeightedCategoryCrossEntropy |  3.29381800\n",
            "Step    690: eval  WeightedCategoryCrossEntropy |  3.30916691\n",
            "Step    690: eval      WeightedCategoryAccuracy |  0.31701630\n",
            "\n",
            "Step    695: Ran 5 train steps in 70.29 secs\n",
            "Step    695: train WeightedCategoryCrossEntropy |  3.45016980\n",
            "Step    695: eval  WeightedCategoryCrossEntropy |  3.60105133\n",
            "Step    695: eval      WeightedCategoryAccuracy |  0.33106062\n",
            "\n",
            "Step    700: Ran 5 train steps in 70.34 secs\n",
            "Step    700: train WeightedCategoryCrossEntropy |  3.53079557\n",
            "Step    700: eval  WeightedCategoryCrossEntropy |  3.21332836\n",
            "Step    700: eval      WeightedCategoryAccuracy |  0.32508144\n",
            "\n",
            "Step    705: Ran 5 train steps in 71.04 secs\n",
            "Step    705: train WeightedCategoryCrossEntropy |  3.32178688\n",
            "Step    705: eval  WeightedCategoryCrossEntropy |  3.26184154\n",
            "Step    705: eval      WeightedCategoryAccuracy |  0.32841328\n",
            "\n",
            "Step    710: Ran 5 train steps in 70.82 secs\n",
            "Step    710: train WeightedCategoryCrossEntropy |  3.37902570\n",
            "Step    710: eval  WeightedCategoryCrossEntropy |  3.39072466\n",
            "Step    710: eval      WeightedCategoryAccuracy |  0.31968811\n",
            "\n",
            "Step    715: Ran 5 train steps in 70.11 secs\n",
            "Step    715: train WeightedCategoryCrossEntropy |  3.34772825\n",
            "Step    715: eval  WeightedCategoryCrossEntropy |  3.37610865\n",
            "Step    715: eval      WeightedCategoryAccuracy |  0.31216457\n",
            "\n",
            "Step    720: Ran 5 train steps in 70.23 secs\n",
            "Step    720: train WeightedCategoryCrossEntropy |  3.34836507\n",
            "Step    720: eval  WeightedCategoryCrossEntropy |  3.24242282\n",
            "Step    720: eval      WeightedCategoryAccuracy |  0.32733813\n",
            "\n",
            "Step    725: Ran 5 train steps in 71.17 secs\n",
            "Step    725: train WeightedCategoryCrossEntropy |  3.41307783\n",
            "Step    725: eval  WeightedCategoryCrossEntropy |  3.51075172\n",
            "Step    725: eval      WeightedCategoryAccuracy |  0.33442408\n",
            "\n",
            "Step    730: Ran 5 train steps in 70.42 secs\n",
            "Step    730: train WeightedCategoryCrossEntropy |  3.41462255\n",
            "Step    730: eval  WeightedCategoryCrossEntropy |  3.27164793\n",
            "Step    730: eval      WeightedCategoryAccuracy |  0.32285890\n",
            "\n",
            "Step    735: Ran 5 train steps in 69.50 secs\n",
            "Step    735: train WeightedCategoryCrossEntropy |  3.40719604\n",
            "Step    735: eval  WeightedCategoryCrossEntropy |  3.28007770\n",
            "Step    735: eval      WeightedCategoryAccuracy |  0.32303619\n",
            "\n",
            "Step    740: Ran 5 train steps in 68.76 secs\n",
            "Step    740: train WeightedCategoryCrossEntropy |  3.41151690\n",
            "Step    740: eval  WeightedCategoryCrossEntropy |  3.35988235\n",
            "Step    740: eval      WeightedCategoryAccuracy |  0.35149863\n",
            "\n",
            "Step    745: Ran 5 train steps in 69.40 secs\n",
            "Step    745: train WeightedCategoryCrossEntropy |  3.35638499\n",
            "Step    745: eval  WeightedCategoryCrossEntropy |  3.26486325\n",
            "Step    745: eval      WeightedCategoryAccuracy |  0.32225063\n",
            "\n",
            "Step    750: Ran 5 train steps in 70.02 secs\n",
            "Step    750: train WeightedCategoryCrossEntropy |  3.30791926\n",
            "Step    750: eval  WeightedCategoryCrossEntropy |  3.50320458\n",
            "Step    750: eval      WeightedCategoryAccuracy |  0.32861897\n",
            "\n",
            "Step    755: Ran 5 train steps in 71.25 secs\n",
            "Step    755: train WeightedCategoryCrossEntropy |  3.32972002\n",
            "Step    755: eval  WeightedCategoryCrossEntropy |  3.22088814\n",
            "Step    755: eval      WeightedCategoryAccuracy |  0.34329233\n",
            "\n",
            "Step    760: Ran 5 train steps in 69.85 secs\n",
            "Step    760: train WeightedCategoryCrossEntropy |  3.49328804\n",
            "Step    760: eval  WeightedCategoryCrossEntropy |  3.31915259\n",
            "Step    760: eval      WeightedCategoryAccuracy |  0.31223628\n",
            "\n",
            "Step    765: Ran 5 train steps in 70.78 secs\n",
            "Step    765: train WeightedCategoryCrossEntropy |  3.34187198\n",
            "Step    765: eval  WeightedCategoryCrossEntropy |  3.25374413\n",
            "Step    765: eval      WeightedCategoryAccuracy |  0.33122364\n",
            "\n",
            "Step    770: Ran 5 train steps in 69.94 secs\n",
            "Step    770: train WeightedCategoryCrossEntropy |  3.30473089\n",
            "Step    770: eval  WeightedCategoryCrossEntropy |  3.34586096\n",
            "Step    770: eval      WeightedCategoryAccuracy |  0.34170040\n",
            "\n",
            "Step    775: Ran 5 train steps in 69.52 secs\n",
            "Step    775: train WeightedCategoryCrossEntropy |  3.37660789\n",
            "Step    775: eval  WeightedCategoryCrossEntropy |  3.33202863\n",
            "Step    775: eval      WeightedCategoryAccuracy |  0.32153752\n",
            "\n",
            "Step    780: Ran 5 train steps in 69.48 secs\n",
            "Step    780: train WeightedCategoryCrossEntropy |  3.31111264\n",
            "Step    780: eval  WeightedCategoryCrossEntropy |  3.28225923\n",
            "Step    780: eval      WeightedCategoryAccuracy |  0.33199999\n",
            "\n",
            "Step    785: Ran 5 train steps in 70.08 secs\n",
            "Step    785: train WeightedCategoryCrossEntropy |  3.32672358\n",
            "Step    785: eval  WeightedCategoryCrossEntropy |  3.27669239\n",
            "Step    785: eval      WeightedCategoryAccuracy |  0.32471627\n",
            "\n",
            "Step    790: Ran 5 train steps in 69.05 secs\n",
            "Step    790: train WeightedCategoryCrossEntropy |  3.42354202\n",
            "Step    790: eval  WeightedCategoryCrossEntropy |  3.32973695\n",
            "Step    790: eval      WeightedCategoryAccuracy |  0.33115610\n",
            "\n",
            "Step    795: Ran 5 train steps in 71.19 secs\n",
            "Step    795: train WeightedCategoryCrossEntropy |  3.28514743\n",
            "Step    795: eval  WeightedCategoryCrossEntropy |  3.36732554\n",
            "Step    795: eval      WeightedCategoryAccuracy |  0.31879607\n",
            "\n",
            "Step    800: Ran 5 train steps in 69.53 secs\n",
            "Step    800: train WeightedCategoryCrossEntropy |  3.32757044\n",
            "Step    800: eval  WeightedCategoryCrossEntropy |  3.69263053\n",
            "Step    800: eval      WeightedCategoryAccuracy |  0.32063076\n",
            "\n",
            "Step    805: Ran 5 train steps in 70.57 secs\n",
            "Step    805: train WeightedCategoryCrossEntropy |  3.31010771\n",
            "Step    805: eval  WeightedCategoryCrossEntropy |  3.37787890\n",
            "Step    805: eval      WeightedCategoryAccuracy |  0.32852563\n",
            "\n",
            "Step    810: Ran 5 train steps in 70.62 secs\n",
            "Step    810: train WeightedCategoryCrossEntropy |  3.27065802\n",
            "Step    810: eval  WeightedCategoryCrossEntropy |  3.34625959\n",
            "Step    810: eval      WeightedCategoryAccuracy |  0.32469305\n",
            "\n",
            "Step    815: Ran 5 train steps in 73.19 secs\n",
            "Step    815: train WeightedCategoryCrossEntropy |  3.30030131\n",
            "Step    815: eval  WeightedCategoryCrossEntropy |  3.21254563\n",
            "Step    815: eval      WeightedCategoryAccuracy |  0.32582584\n",
            "\n",
            "Step    820: Ran 5 train steps in 73.57 secs\n",
            "Step    820: train WeightedCategoryCrossEntropy |  3.42742682\n",
            "Step    820: eval  WeightedCategoryCrossEntropy |  3.34405327\n",
            "Step    820: eval      WeightedCategoryAccuracy |  0.32660168\n",
            "\n",
            "Step    825: Ran 5 train steps in 71.93 secs\n",
            "Step    825: train WeightedCategoryCrossEntropy |  3.45955324\n",
            "Step    825: eval  WeightedCategoryCrossEntropy |  3.56680703\n",
            "Step    825: eval      WeightedCategoryAccuracy |  0.31582734\n",
            "\n",
            "Step    830: Ran 5 train steps in 72.67 secs\n",
            "Step    830: train WeightedCategoryCrossEntropy |  3.43103528\n",
            "Step    830: eval  WeightedCategoryCrossEntropy |  3.42623496\n",
            "Step    830: eval      WeightedCategoryAccuracy |  0.30621171\n",
            "\n",
            "Step    835: Ran 5 train steps in 71.20 secs\n",
            "Step    835: train WeightedCategoryCrossEntropy |  3.45186090\n",
            "Step    835: eval  WeightedCategoryCrossEntropy |  3.25982165\n",
            "Step    835: eval      WeightedCategoryAccuracy |  0.34412265\n",
            "\n",
            "Step    840: Ran 5 train steps in 70.15 secs\n",
            "Step    840: train WeightedCategoryCrossEntropy |  3.36067390\n",
            "Step    840: eval  WeightedCategoryCrossEntropy |  3.32465649\n",
            "Step    840: eval      WeightedCategoryAccuracy |  0.33414337\n",
            "\n",
            "Step    845: Ran 5 train steps in 71.51 secs\n",
            "Step    845: train WeightedCategoryCrossEntropy |  3.30195546\n",
            "Step    845: eval  WeightedCategoryCrossEntropy |  3.30099177\n",
            "Step    845: eval      WeightedCategoryAccuracy |  0.33658171\n",
            "\n",
            "Step    850: Ran 5 train steps in 70.19 secs\n",
            "Step    850: train WeightedCategoryCrossEntropy |  3.35166168\n",
            "Step    850: eval  WeightedCategoryCrossEntropy |  3.20896006\n",
            "Step    850: eval      WeightedCategoryAccuracy |  0.33648649\n",
            "\n",
            "Step    855: Ran 5 train steps in 69.82 secs\n",
            "Step    855: train WeightedCategoryCrossEntropy |  3.31951332\n",
            "Step    855: eval  WeightedCategoryCrossEntropy |  3.31239533\n",
            "Step    855: eval      WeightedCategoryAccuracy |  0.32081378\n",
            "\n",
            "Step    860: Ran 5 train steps in 70.00 secs\n",
            "Step    860: train WeightedCategoryCrossEntropy |  3.40527272\n",
            "Step    860: eval  WeightedCategoryCrossEntropy |  3.42432189\n",
            "Step    860: eval      WeightedCategoryAccuracy |  0.30112165\n",
            "\n",
            "Step    865: Ran 5 train steps in 70.60 secs\n",
            "Step    865: train WeightedCategoryCrossEntropy |  3.30675960\n",
            "Step    865: eval  WeightedCategoryCrossEntropy |  3.49121642\n",
            "Step    865: eval      WeightedCategoryAccuracy |  0.31803897\n",
            "\n",
            "Step    870: Ran 5 train steps in 69.02 secs\n",
            "Step    870: train WeightedCategoryCrossEntropy |  3.35993695\n",
            "Step    870: eval  WeightedCategoryCrossEntropy |  3.31725550\n",
            "Step    870: eval      WeightedCategoryAccuracy |  0.33079365\n",
            "\n",
            "Step    875: Ran 5 train steps in 69.78 secs\n",
            "Step    875: train WeightedCategoryCrossEntropy |  3.43831944\n",
            "Step    875: eval  WeightedCategoryCrossEntropy |  3.18003392\n",
            "Step    875: eval      WeightedCategoryAccuracy |  0.35873231\n",
            "\n",
            "Step    880: Ran 5 train steps in 69.72 secs\n",
            "Step    880: train WeightedCategoryCrossEntropy |  3.34512448\n",
            "Step    880: eval  WeightedCategoryCrossEntropy |  3.26961374\n",
            "Step    880: eval      WeightedCategoryAccuracy |  0.33098590\n",
            "\n",
            "Step    885: Ran 5 train steps in 68.63 secs\n",
            "Step    885: train WeightedCategoryCrossEntropy |  3.27002382\n",
            "Step    885: eval  WeightedCategoryCrossEntropy |  3.13692665\n",
            "Step    885: eval      WeightedCategoryAccuracy |  0.33489305\n",
            "\n",
            "Step    890: Ran 5 train steps in 84.58 secs\n",
            "Step    890: train WeightedCategoryCrossEntropy |  3.38577032\n",
            "Step    890: eval  WeightedCategoryCrossEntropy |  3.17611384\n",
            "Step    890: eval      WeightedCategoryAccuracy |  0.33301526\n",
            "\n",
            "Step    895: Ran 5 train steps in 70.66 secs\n",
            "Step    895: train WeightedCategoryCrossEntropy |  3.39567804\n",
            "Step    895: eval  WeightedCategoryCrossEntropy |  3.22242188\n",
            "Step    895: eval      WeightedCategoryAccuracy |  0.32606199\n",
            "\n",
            "Step    900: Ran 5 train steps in 71.56 secs\n",
            "Step    900: train WeightedCategoryCrossEntropy |  3.29682779\n",
            "Step    900: eval  WeightedCategoryCrossEntropy |  3.65011096\n",
            "Step    900: eval      WeightedCategoryAccuracy |  0.30415562\n",
            "\n",
            "Step    905: Ran 5 train steps in 69.46 secs\n",
            "Step    905: train WeightedCategoryCrossEntropy |  3.44054031\n",
            "Step    905: eval  WeightedCategoryCrossEntropy |  3.36963844\n",
            "Step    905: eval      WeightedCategoryAccuracy |  0.32048929\n",
            "\n",
            "Step    910: Ran 5 train steps in 69.65 secs\n",
            "Step    910: train WeightedCategoryCrossEntropy |  3.31388092\n",
            "Step    910: eval  WeightedCategoryCrossEntropy |  3.58958459\n",
            "Step    910: eval      WeightedCategoryAccuracy |  0.30280373\n",
            "\n",
            "Step    915: Ran 5 train steps in 69.96 secs\n",
            "Step    915: train WeightedCategoryCrossEntropy |  3.33587646\n",
            "Step    915: eval  WeightedCategoryCrossEntropy |  3.42906022\n",
            "Step    915: eval      WeightedCategoryAccuracy |  0.32307693\n",
            "\n",
            "Step    920: Ran 5 train steps in 70.48 secs\n",
            "Step    920: train WeightedCategoryCrossEntropy |  3.43478918\n",
            "Step    920: eval  WeightedCategoryCrossEntropy |  3.35767484\n",
            "Step    920: eval      WeightedCategoryAccuracy |  0.30560580\n",
            "\n",
            "Step    925: Ran 5 train steps in 70.04 secs\n",
            "Step    925: train WeightedCategoryCrossEntropy |  3.35768843\n",
            "Step    925: eval  WeightedCategoryCrossEntropy |  3.36757278\n",
            "Step    925: eval      WeightedCategoryAccuracy |  0.32375479\n",
            "\n",
            "Step    930: Ran 5 train steps in 70.35 secs\n",
            "Step    930: train WeightedCategoryCrossEntropy |  3.37315178\n",
            "Step    930: eval  WeightedCategoryCrossEntropy |  3.24686837\n",
            "Step    930: eval      WeightedCategoryAccuracy |  0.32857144\n",
            "\n",
            "Step    935: Ran 5 train steps in 70.43 secs\n",
            "Step    935: train WeightedCategoryCrossEntropy |  3.42226839\n",
            "Step    935: eval  WeightedCategoryCrossEntropy |  3.31894636\n",
            "Step    935: eval      WeightedCategoryAccuracy |  0.33588272\n",
            "\n",
            "Step    940: Ran 5 train steps in 69.54 secs\n",
            "Step    940: train WeightedCategoryCrossEntropy |  3.33327603\n",
            "Step    940: eval  WeightedCategoryCrossEntropy |  3.39922237\n",
            "Step    940: eval      WeightedCategoryAccuracy |  0.29562739\n",
            "\n",
            "Step    945: Ran 5 train steps in 70.42 secs\n",
            "Step    945: train WeightedCategoryCrossEntropy |  3.38385439\n",
            "Step    945: eval  WeightedCategoryCrossEntropy |  3.49094605\n",
            "Step    945: eval      WeightedCategoryAccuracy |  0.32585084\n",
            "\n",
            "Step    950: Ran 5 train steps in 71.78 secs\n",
            "Step    950: train WeightedCategoryCrossEntropy |  3.29671741\n",
            "Step    950: eval  WeightedCategoryCrossEntropy |  3.33437991\n",
            "Step    950: eval      WeightedCategoryAccuracy |  0.33649853\n",
            "\n",
            "Step    955: Ran 5 train steps in 70.70 secs\n",
            "Step    955: train WeightedCategoryCrossEntropy |  3.50486231\n",
            "Step    955: eval  WeightedCategoryCrossEntropy |  3.33769941\n",
            "Step    955: eval      WeightedCategoryAccuracy |  0.33918670\n",
            "\n",
            "Step    960: Ran 5 train steps in 70.19 secs\n",
            "Step    960: train WeightedCategoryCrossEntropy |  3.45069075\n",
            "Step    960: eval  WeightedCategoryCrossEntropy |  3.34349418\n",
            "Step    960: eval      WeightedCategoryAccuracy |  0.32619557\n",
            "\n",
            "Step    965: Ran 5 train steps in 70.37 secs\n",
            "Step    965: train WeightedCategoryCrossEntropy |  3.36538267\n",
            "Step    965: eval  WeightedCategoryCrossEntropy |  3.42687249\n",
            "Step    965: eval      WeightedCategoryAccuracy |  0.31311801\n",
            "\n",
            "Step    970: Ran 5 train steps in 70.80 secs\n",
            "Step    970: train WeightedCategoryCrossEntropy |  3.44161940\n",
            "Step    970: eval  WeightedCategoryCrossEntropy |  3.33919263\n",
            "Step    970: eval      WeightedCategoryAccuracy |  0.31974250\n",
            "\n",
            "Step    975: Ran 5 train steps in 70.59 secs\n",
            "Step    975: train WeightedCategoryCrossEntropy |  3.45757437\n",
            "Step    975: eval  WeightedCategoryCrossEntropy |  3.67737842\n",
            "Step    975: eval      WeightedCategoryAccuracy |  0.30677587\n",
            "\n",
            "Step    980: Ran 5 train steps in 70.71 secs\n",
            "Step    980: train WeightedCategoryCrossEntropy |  3.37799597\n",
            "Step    980: eval  WeightedCategoryCrossEntropy |  3.32786393\n",
            "Step    980: eval      WeightedCategoryAccuracy |  0.32741842\n",
            "\n",
            "Step    985: Ran 5 train steps in 69.93 secs\n",
            "Step    985: train WeightedCategoryCrossEntropy |  3.42505980\n",
            "Step    985: eval  WeightedCategoryCrossEntropy |  3.45359898\n",
            "Step    985: eval      WeightedCategoryAccuracy |  0.30658785\n",
            "\n",
            "Step    990: Ran 5 train steps in 71.41 secs\n",
            "Step    990: train WeightedCategoryCrossEntropy |  3.36760831\n",
            "Step    990: eval  WeightedCategoryCrossEntropy |  3.33684874\n",
            "Step    990: eval      WeightedCategoryAccuracy |  0.34039819\n",
            "\n",
            "Step    995: Ran 5 train steps in 71.35 secs\n",
            "Step    995: train WeightedCategoryCrossEntropy |  3.41800165\n",
            "Step    995: eval  WeightedCategoryCrossEntropy |  3.30182576\n",
            "Step    995: eval      WeightedCategoryAccuracy |  0.35404143\n",
            "\n",
            "Step   1000: Ran 5 train steps in 71.86 secs\n",
            "Step   1000: train WeightedCategoryCrossEntropy |  3.29422307\n",
            "Step   1000: eval  WeightedCategoryCrossEntropy |  3.30118608\n",
            "Step   1000: eval      WeightedCategoryAccuracy |  0.31325302\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwI79miua11r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64074cee-2efe-4c2c-e221-be5a3bcbf0ee"
      },
      "source": [
        "loop.run(TRAIN_STEPS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/jax/lib/xla_bridge.py:304: UserWarning: jax.host_id has been renamed to jax.process_index. This alias will eventually be removed; please update your code.\n",
            "  \"jax.host_id has been renamed to jax.process_index. This alias \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Step   1005: Ran 5 train steps in 71.76 secs\n",
            "Step   1005: train WeightedCategoryCrossEntropy |  3.44074559\n",
            "Step   1005: eval  WeightedCategoryCrossEntropy |  3.34850526\n",
            "Step   1005: eval      WeightedCategoryAccuracy |  0.32222223\n",
            "\n",
            "Step   1010: Ran 5 train steps in 70.59 secs\n",
            "Step   1010: train WeightedCategoryCrossEntropy |  3.50347400\n",
            "Step   1010: eval  WeightedCategoryCrossEntropy |  3.37727499\n",
            "Step   1010: eval      WeightedCategoryAccuracy |  0.31296450\n",
            "\n",
            "Step   1015: Ran 5 train steps in 70.47 secs\n",
            "Step   1015: train WeightedCategoryCrossEntropy |  3.43329811\n",
            "Step   1015: eval  WeightedCategoryCrossEntropy |  3.38387275\n",
            "Step   1015: eval      WeightedCategoryAccuracy |  0.32614380\n",
            "\n",
            "Step   1020: Ran 5 train steps in 72.20 secs\n",
            "Step   1020: train WeightedCategoryCrossEntropy |  3.47485161\n",
            "Step   1020: eval  WeightedCategoryCrossEntropy |  3.41472888\n",
            "Step   1020: eval      WeightedCategoryAccuracy |  0.33101448\n",
            "\n",
            "Step   1025: Ran 5 train steps in 70.23 secs\n",
            "Step   1025: train WeightedCategoryCrossEntropy |  3.45781469\n",
            "Step   1025: eval  WeightedCategoryCrossEntropy |  3.36288619\n",
            "Step   1025: eval      WeightedCategoryAccuracy |  0.32571429\n",
            "\n",
            "Step   1030: Ran 5 train steps in 71.42 secs\n",
            "Step   1030: train WeightedCategoryCrossEntropy |  3.33764148\n",
            "Step   1030: eval  WeightedCategoryCrossEntropy |  3.30851245\n",
            "Step   1030: eval      WeightedCategoryAccuracy |  0.34567901\n",
            "\n",
            "Step   1035: Ran 5 train steps in 70.03 secs\n",
            "Step   1035: train WeightedCategoryCrossEntropy |  3.46292734\n",
            "Step   1035: eval  WeightedCategoryCrossEntropy |  3.37965989\n",
            "Step   1035: eval      WeightedCategoryAccuracy |  0.33135313\n",
            "\n",
            "Step   1040: Ran 5 train steps in 70.72 secs\n",
            "Step   1040: train WeightedCategoryCrossEntropy |  3.45371175\n",
            "Step   1040: eval  WeightedCategoryCrossEntropy |  3.56216478\n",
            "Step   1040: eval      WeightedCategoryAccuracy |  0.31344470\n",
            "\n",
            "Step   1045: Ran 5 train steps in 70.79 secs\n",
            "Step   1045: train WeightedCategoryCrossEntropy |  3.36407280\n",
            "Step   1045: eval  WeightedCategoryCrossEntropy |  3.44835162\n",
            "Step   1045: eval      WeightedCategoryAccuracy |  0.33054891\n",
            "\n",
            "Step   1050: Ran 5 train steps in 75.61 secs\n",
            "Step   1050: train WeightedCategoryCrossEntropy |  3.48688364\n",
            "Step   1050: eval  WeightedCategoryCrossEntropy |  3.40250087\n",
            "Step   1050: eval      WeightedCategoryAccuracy |  0.31001890\n",
            "\n",
            "Step   1055: Ran 5 train steps in 72.08 secs\n",
            "Step   1055: train WeightedCategoryCrossEntropy |  3.38435435\n",
            "Step   1055: eval  WeightedCategoryCrossEntropy |  3.47071934\n",
            "Step   1055: eval      WeightedCategoryAccuracy |  0.31338322\n",
            "\n",
            "Step   1060: Ran 5 train steps in 71.05 secs\n",
            "Step   1060: train WeightedCategoryCrossEntropy |  3.38945889\n",
            "Step   1060: eval  WeightedCategoryCrossEntropy |  3.45613027\n",
            "Step   1060: eval      WeightedCategoryAccuracy |  0.30724299\n",
            "\n",
            "Step   1065: Ran 5 train steps in 71.49 secs\n",
            "Step   1065: train WeightedCategoryCrossEntropy |  3.42563772\n",
            "Step   1065: eval  WeightedCategoryCrossEntropy |  3.56401110\n",
            "Step   1065: eval      WeightedCategoryAccuracy |  0.31498259\n",
            "\n",
            "Step   1070: Ran 5 train steps in 70.76 secs\n",
            "Step   1070: train WeightedCategoryCrossEntropy |  3.43816519\n",
            "Step   1070: eval  WeightedCategoryCrossEntropy |  3.44022799\n",
            "Step   1070: eval      WeightedCategoryAccuracy |  0.30731708\n",
            "\n",
            "Step   1075: Ran 5 train steps in 71.00 secs\n",
            "Step   1075: train WeightedCategoryCrossEntropy |  3.43088531\n",
            "Step   1075: eval  WeightedCategoryCrossEntropy |  3.44783139\n",
            "Step   1075: eval      WeightedCategoryAccuracy |  0.30093458\n",
            "\n",
            "Step   1080: Ran 5 train steps in 70.29 secs\n",
            "Step   1080: train WeightedCategoryCrossEntropy |  3.35876465\n",
            "Step   1080: eval  WeightedCategoryCrossEntropy |  3.50678396\n",
            "Step   1080: eval      WeightedCategoryAccuracy |  0.32534680\n",
            "\n",
            "Step   1085: Ran 5 train steps in 69.74 secs\n",
            "Step   1085: train WeightedCategoryCrossEntropy |  3.39970660\n",
            "Step   1085: eval  WeightedCategoryCrossEntropy |  3.42495227\n",
            "Step   1085: eval      WeightedCategoryAccuracy |  0.30398986\n",
            "\n",
            "Step   1090: Ran 5 train steps in 69.74 secs\n",
            "Step   1090: train WeightedCategoryCrossEntropy |  3.49396753\n",
            "Step   1090: eval  WeightedCategoryCrossEntropy |  3.42421126\n",
            "Step   1090: eval      WeightedCategoryAccuracy |  0.31901839\n",
            "\n",
            "Step   1095: Ran 5 train steps in 69.67 secs\n",
            "Step   1095: train WeightedCategoryCrossEntropy |  3.46143723\n",
            "Step   1095: eval  WeightedCategoryCrossEntropy |  3.36482334\n",
            "Step   1095: eval      WeightedCategoryAccuracy |  0.32651716\n",
            "\n",
            "Step   1100: Ran 5 train steps in 72.43 secs\n",
            "Step   1100: train WeightedCategoryCrossEntropy |  3.37581825\n",
            "Step   1100: eval  WeightedCategoryCrossEntropy |  3.34149528\n",
            "Step   1100: eval      WeightedCategoryAccuracy |  0.32678455\n",
            "\n",
            "Step   1105: Ran 5 train steps in 70.48 secs\n",
            "Step   1105: train WeightedCategoryCrossEntropy |  3.40215254\n",
            "Step   1105: eval  WeightedCategoryCrossEntropy |  3.46579051\n",
            "Step   1105: eval      WeightedCategoryAccuracy |  0.31240064\n",
            "\n",
            "Step   1110: Ran 5 train steps in 70.10 secs\n",
            "Step   1110: train WeightedCategoryCrossEntropy |  3.38708067\n",
            "Step   1110: eval  WeightedCategoryCrossEntropy |  3.75122857\n",
            "Step   1110: eval      WeightedCategoryAccuracy |  0.29231817\n",
            "\n",
            "Step   1115: Ran 5 train steps in 70.57 secs\n",
            "Step   1115: train WeightedCategoryCrossEntropy |  3.46991086\n",
            "Step   1115: eval  WeightedCategoryCrossEntropy |  3.37090945\n",
            "Step   1115: eval      WeightedCategoryAccuracy |  0.28669527\n",
            "\n",
            "Step   1120: Ran 5 train steps in 71.05 secs\n",
            "Step   1120: train WeightedCategoryCrossEntropy |  3.40360260\n",
            "Step   1120: eval  WeightedCategoryCrossEntropy |  3.49603033\n",
            "Step   1120: eval      WeightedCategoryAccuracy |  0.32263419\n",
            "\n",
            "Step   1125: Ran 5 train steps in 72.72 secs\n",
            "Step   1125: train WeightedCategoryCrossEntropy |  3.41255236\n",
            "Step   1125: eval  WeightedCategoryCrossEntropy |  3.40645719\n",
            "Step   1125: eval      WeightedCategoryAccuracy |  0.33554617\n",
            "\n",
            "Step   1130: Ran 5 train steps in 71.18 secs\n",
            "Step   1130: train WeightedCategoryCrossEntropy |  3.37648082\n",
            "Step   1130: eval  WeightedCategoryCrossEntropy |  3.44105101\n",
            "Step   1130: eval      WeightedCategoryAccuracy |  0.29807693\n",
            "\n",
            "Step   1135: Ran 5 train steps in 71.39 secs\n",
            "Step   1135: train WeightedCategoryCrossEntropy |  3.33559680\n",
            "Step   1135: eval  WeightedCategoryCrossEntropy |  3.36576796\n",
            "Step   1135: eval      WeightedCategoryAccuracy |  0.31650135\n",
            "\n",
            "Step   1140: Ran 5 train steps in 71.68 secs\n",
            "Step   1140: train WeightedCategoryCrossEntropy |  3.36641169\n",
            "Step   1140: eval  WeightedCategoryCrossEntropy |  3.23405218\n",
            "Step   1140: eval      WeightedCategoryAccuracy |  0.32896239\n",
            "\n",
            "Step   1145: Ran 5 train steps in 71.65 secs\n",
            "Step   1145: train WeightedCategoryCrossEntropy |  3.28034592\n",
            "Step   1145: eval  WeightedCategoryCrossEntropy |  3.54469347\n",
            "Step   1145: eval      WeightedCategoryAccuracy |  0.30476192\n",
            "\n",
            "Step   1150: Ran 5 train steps in 72.23 secs\n",
            "Step   1150: train WeightedCategoryCrossEntropy |  3.26058578\n",
            "Step   1150: eval  WeightedCategoryCrossEntropy |  3.16796088\n",
            "Step   1150: eval      WeightedCategoryAccuracy |  0.31801471\n",
            "\n",
            "Step   1155: Ran 5 train steps in 71.53 secs\n",
            "Step   1155: train WeightedCategoryCrossEntropy |  3.36725354\n",
            "Step   1155: eval  WeightedCategoryCrossEntropy |  3.28957605\n",
            "Step   1155: eval      WeightedCategoryAccuracy |  0.31279305\n",
            "\n",
            "Step   1160: Ran 5 train steps in 72.85 secs\n",
            "Step   1160: train WeightedCategoryCrossEntropy |  3.34685755\n",
            "Step   1160: eval  WeightedCategoryCrossEntropy |  3.20030689\n",
            "Step   1160: eval      WeightedCategoryAccuracy |  0.32888889\n",
            "\n",
            "Step   1165: Ran 5 train steps in 69.91 secs\n",
            "Step   1165: train WeightedCategoryCrossEntropy |  3.41884565\n",
            "Step   1165: eval  WeightedCategoryCrossEntropy |  3.51265788\n",
            "Step   1165: eval      WeightedCategoryAccuracy |  0.31178162\n",
            "\n",
            "Step   1170: Ran 5 train steps in 71.12 secs\n",
            "Step   1170: train WeightedCategoryCrossEntropy |  3.37701726\n",
            "Step   1170: eval  WeightedCategoryCrossEntropy |  3.42382669\n",
            "Step   1170: eval      WeightedCategoryAccuracy |  0.31857032\n",
            "\n",
            "Step   1175: Ran 5 train steps in 73.07 secs\n",
            "Step   1175: train WeightedCategoryCrossEntropy |  3.38071775\n",
            "Step   1175: eval  WeightedCategoryCrossEntropy |  3.42198396\n",
            "Step   1175: eval      WeightedCategoryAccuracy |  0.31798807\n",
            "\n",
            "Step   1180: Ran 5 train steps in 70.57 secs\n",
            "Step   1180: train WeightedCategoryCrossEntropy |  3.42378306\n",
            "Step   1180: eval  WeightedCategoryCrossEntropy |  3.28061318\n",
            "Step   1180: eval      WeightedCategoryAccuracy |  0.32542372\n",
            "\n",
            "Step   1185: Ran 5 train steps in 77.99 secs\n",
            "Step   1185: train WeightedCategoryCrossEntropy |  3.38125682\n",
            "Step   1185: eval  WeightedCategoryCrossEntropy |  3.41181302\n",
            "Step   1185: eval      WeightedCategoryAccuracy |  0.32826537\n",
            "\n",
            "Step   1190: Ran 5 train steps in 71.90 secs\n",
            "Step   1190: train WeightedCategoryCrossEntropy |  3.43456030\n",
            "Step   1190: eval  WeightedCategoryCrossEntropy |  3.32083344\n",
            "Step   1190: eval      WeightedCategoryAccuracy |  0.32586208\n",
            "\n",
            "Step   1195: Ran 5 train steps in 71.70 secs\n",
            "Step   1195: train WeightedCategoryCrossEntropy |  3.38371968\n",
            "Step   1195: eval  WeightedCategoryCrossEntropy |  3.34899712\n",
            "Step   1195: eval      WeightedCategoryAccuracy |  0.31183368\n",
            "\n",
            "Step   1200: Ran 5 train steps in 70.14 secs\n",
            "Step   1200: train WeightedCategoryCrossEntropy |  3.38479161\n",
            "Step   1200: eval  WeightedCategoryCrossEntropy |  3.41760230\n",
            "Step   1200: eval      WeightedCategoryAccuracy |  0.30495170\n",
            "\n",
            "Step   1205: Ran 5 train steps in 70.57 secs\n",
            "Step   1205: train WeightedCategoryCrossEntropy |  3.43343234\n",
            "Step   1205: eval  WeightedCategoryCrossEntropy |  3.56751442\n",
            "Step   1205: eval      WeightedCategoryAccuracy |  0.29787233\n",
            "\n",
            "Step   1210: Ran 5 train steps in 71.07 secs\n",
            "Step   1210: train WeightedCategoryCrossEntropy |  3.34203100\n",
            "Step   1210: eval  WeightedCategoryCrossEntropy |  3.47024441\n",
            "Step   1210: eval      WeightedCategoryAccuracy |  0.31533846\n",
            "\n",
            "Step   1215: Ran 5 train steps in 70.66 secs\n",
            "Step   1215: train WeightedCategoryCrossEntropy |  3.35561109\n",
            "Step   1215: eval  WeightedCategoryCrossEntropy |  3.42002153\n",
            "Step   1215: eval      WeightedCategoryAccuracy |  0.32027364\n",
            "\n",
            "Step   1220: Ran 5 train steps in 71.23 secs\n",
            "Step   1220: train WeightedCategoryCrossEntropy |  3.35705996\n",
            "Step   1220: eval  WeightedCategoryCrossEntropy |  3.39616203\n",
            "Step   1220: eval      WeightedCategoryAccuracy |  0.33310857\n",
            "\n",
            "Step   1225: Ran 5 train steps in 72.70 secs\n",
            "Step   1225: train WeightedCategoryCrossEntropy |  3.24810457\n",
            "Step   1225: eval  WeightedCategoryCrossEntropy |  3.27804518\n",
            "Step   1225: eval      WeightedCategoryAccuracy |  0.32866481\n",
            "\n",
            "Step   1230: Ran 5 train steps in 71.98 secs\n",
            "Step   1230: train WeightedCategoryCrossEntropy |  3.36807942\n",
            "Step   1230: eval  WeightedCategoryCrossEntropy |  3.34286070\n",
            "Step   1230: eval      WeightedCategoryAccuracy |  0.32317072\n",
            "\n",
            "Step   1235: Ran 5 train steps in 71.09 secs\n",
            "Step   1235: train WeightedCategoryCrossEntropy |  3.35619593\n",
            "Step   1235: eval  WeightedCategoryCrossEntropy |  3.32781863\n",
            "Step   1235: eval      WeightedCategoryAccuracy |  0.31537449\n",
            "\n",
            "Step   1240: Ran 5 train steps in 70.65 secs\n",
            "Step   1240: train WeightedCategoryCrossEntropy |  3.38321447\n",
            "Step   1240: eval  WeightedCategoryCrossEntropy |  3.29327154\n",
            "Step   1240: eval      WeightedCategoryAccuracy |  0.33060667\n",
            "\n",
            "Step   1245: Ran 5 train steps in 70.20 secs\n",
            "Step   1245: train WeightedCategoryCrossEntropy |  3.35086632\n",
            "Step   1245: eval  WeightedCategoryCrossEntropy |  3.37506795\n",
            "Step   1245: eval      WeightedCategoryAccuracy |  0.30663329\n",
            "\n",
            "Step   1250: Ran 5 train steps in 70.26 secs\n",
            "Step   1250: train WeightedCategoryCrossEntropy |  3.40386081\n",
            "Step   1250: eval  WeightedCategoryCrossEntropy |  3.36481142\n",
            "Step   1250: eval      WeightedCategoryAccuracy |  0.31154156\n",
            "\n",
            "Step   1255: Ran 5 train steps in 70.65 secs\n",
            "Step   1255: train WeightedCategoryCrossEntropy |  3.37870860\n",
            "Step   1255: eval  WeightedCategoryCrossEntropy |  3.35721898\n",
            "Step   1255: eval      WeightedCategoryAccuracy |  0.34168705\n",
            "\n",
            "Step   1260: Ran 5 train steps in 70.08 secs\n",
            "Step   1260: train WeightedCategoryCrossEntropy |  3.42090273\n",
            "Step   1260: eval  WeightedCategoryCrossEntropy |  3.23213720\n",
            "Step   1260: eval      WeightedCategoryAccuracy |  0.31996793\n",
            "\n",
            "Step   1265: Ran 5 train steps in 70.36 secs\n",
            "Step   1265: train WeightedCategoryCrossEntropy |  3.36381269\n",
            "Step   1265: eval  WeightedCategoryCrossEntropy |  3.36137700\n",
            "Step   1265: eval      WeightedCategoryAccuracy |  0.29583874\n",
            "\n",
            "Step   1270: Ran 5 train steps in 69.32 secs\n",
            "Step   1270: train WeightedCategoryCrossEntropy |  3.43630028\n",
            "Step   1270: eval  WeightedCategoryCrossEntropy |  3.38100863\n",
            "Step   1270: eval      WeightedCategoryAccuracy |  0.30967337\n",
            "\n",
            "Step   1275: Ran 5 train steps in 69.86 secs\n",
            "Step   1275: train WeightedCategoryCrossEntropy |  3.53580356\n",
            "Step   1275: eval  WeightedCategoryCrossEntropy |  3.44766617\n",
            "Step   1275: eval      WeightedCategoryAccuracy |  0.31215847\n",
            "\n",
            "Step   1280: Ran 5 train steps in 70.12 secs\n",
            "Step   1280: train WeightedCategoryCrossEntropy |  3.48376203\n",
            "Step   1280: eval  WeightedCategoryCrossEntropy |  3.51515412\n",
            "Step   1280: eval      WeightedCategoryAccuracy |  0.30259562\n",
            "\n",
            "Step   1285: Ran 5 train steps in 71.01 secs\n",
            "Step   1285: train WeightedCategoryCrossEntropy |  3.43914723\n",
            "Step   1285: eval  WeightedCategoryCrossEntropy |  3.45736766\n",
            "Step   1285: eval      WeightedCategoryAccuracy |  0.30108359\n",
            "\n",
            "Step   1290: Ran 5 train steps in 69.50 secs\n",
            "Step   1290: train WeightedCategoryCrossEntropy |  3.49115109\n",
            "Step   1290: eval  WeightedCategoryCrossEntropy |  3.48951459\n",
            "Step   1290: eval      WeightedCategoryAccuracy |  0.31114131\n",
            "\n",
            "Step   1295: Ran 5 train steps in 70.07 secs\n",
            "Step   1295: train WeightedCategoryCrossEntropy |  3.42641687\n",
            "Step   1295: eval  WeightedCategoryCrossEntropy |  3.44582486\n",
            "Step   1295: eval      WeightedCategoryAccuracy |  0.31067961\n",
            "\n",
            "Step   1300: Ran 5 train steps in 74.33 secs\n",
            "Step   1300: train WeightedCategoryCrossEntropy |  3.48829985\n",
            "Step   1300: eval  WeightedCategoryCrossEntropy |  3.55494070\n",
            "Step   1300: eval      WeightedCategoryAccuracy |  0.31835207\n",
            "\n",
            "Step   1305: Ran 5 train steps in 78.63 secs\n",
            "Step   1305: train WeightedCategoryCrossEntropy |  3.30165935\n",
            "Step   1305: eval  WeightedCategoryCrossEntropy |  3.40279651\n",
            "Step   1305: eval      WeightedCategoryAccuracy |  0.32959905\n",
            "\n",
            "Step   1310: Ran 5 train steps in 69.32 secs\n",
            "Step   1310: train WeightedCategoryCrossEntropy |  3.45292020\n",
            "Step   1310: eval  WeightedCategoryCrossEntropy |  3.45820236\n",
            "Step   1310: eval      WeightedCategoryAccuracy |  0.31921569\n",
            "\n",
            "Step   1315: Ran 5 train steps in 70.34 secs\n",
            "Step   1315: train WeightedCategoryCrossEntropy |  3.39063954\n",
            "Step   1315: eval  WeightedCategoryCrossEntropy |  3.37332630\n",
            "Step   1315: eval      WeightedCategoryAccuracy |  0.32294428\n",
            "\n",
            "Step   1320: Ran 5 train steps in 70.38 secs\n",
            "Step   1320: train WeightedCategoryCrossEntropy |  3.39235544\n",
            "Step   1320: eval  WeightedCategoryCrossEntropy |  3.25589919\n",
            "Step   1320: eval      WeightedCategoryAccuracy |  0.32363316\n",
            "\n",
            "Step   1325: Ran 5 train steps in 69.47 secs\n",
            "Step   1325: train WeightedCategoryCrossEntropy |  3.45336533\n",
            "Step   1325: eval  WeightedCategoryCrossEntropy |  3.26063251\n",
            "Step   1325: eval      WeightedCategoryAccuracy |  0.33909574\n",
            "\n",
            "Step   1330: Ran 5 train steps in 70.95 secs\n",
            "Step   1330: train WeightedCategoryCrossEntropy |  3.40324783\n",
            "Step   1330: eval  WeightedCategoryCrossEntropy |  3.27782154\n",
            "Step   1330: eval      WeightedCategoryAccuracy |  0.32522997\n",
            "\n",
            "Step   1335: Ran 5 train steps in 70.73 secs\n",
            "Step   1335: train WeightedCategoryCrossEntropy |  3.45473623\n",
            "Step   1335: eval  WeightedCategoryCrossEntropy |  3.50161052\n",
            "Step   1335: eval      WeightedCategoryAccuracy |  0.32123411\n",
            "\n",
            "Step   1340: Ran 5 train steps in 70.06 secs\n",
            "Step   1340: train WeightedCategoryCrossEntropy |  3.41917229\n",
            "Step   1340: eval  WeightedCategoryCrossEntropy |  3.44475007\n",
            "Step   1340: eval      WeightedCategoryAccuracy |  0.33310345\n",
            "\n",
            "Step   1345: Ran 5 train steps in 69.71 secs\n",
            "Step   1345: train WeightedCategoryCrossEntropy |  3.45162320\n",
            "Step   1345: eval  WeightedCategoryCrossEntropy |  3.56962419\n",
            "Step   1345: eval      WeightedCategoryAccuracy |  0.30992270\n",
            "\n",
            "Step   1350: Ran 5 train steps in 70.25 secs\n",
            "Step   1350: train WeightedCategoryCrossEntropy |  3.41323042\n",
            "Step   1350: eval  WeightedCategoryCrossEntropy |  3.35126543\n",
            "Step   1350: eval      WeightedCategoryAccuracy |  0.32199547\n",
            "\n",
            "Step   1355: Ran 5 train steps in 70.66 secs\n",
            "Step   1355: train WeightedCategoryCrossEntropy |  3.42081451\n",
            "Step   1355: eval  WeightedCategoryCrossEntropy |  3.48970413\n",
            "Step   1355: eval      WeightedCategoryAccuracy |  0.31775069\n",
            "\n",
            "Step   1360: Ran 5 train steps in 70.53 secs\n",
            "Step   1360: train WeightedCategoryCrossEntropy |  3.46529818\n",
            "Step   1360: eval  WeightedCategoryCrossEntropy |  3.39975142\n",
            "Step   1360: eval      WeightedCategoryAccuracy |  0.31742424\n",
            "\n",
            "Step   1365: Ran 5 train steps in 68.11 secs\n",
            "Step   1365: train WeightedCategoryCrossEntropy |  3.43855548\n",
            "Step   1365: eval  WeightedCategoryCrossEntropy |  3.31660056\n",
            "Step   1365: eval      WeightedCategoryAccuracy |  0.30949518\n",
            "\n",
            "Step   1370: Ran 5 train steps in 69.86 secs\n",
            "Step   1370: train WeightedCategoryCrossEntropy |  3.35041118\n",
            "Step   1370: eval  WeightedCategoryCrossEntropy |  3.39809823\n",
            "Step   1370: eval      WeightedCategoryAccuracy |  0.32508361\n",
            "\n",
            "Step   1375: Ran 5 train steps in 69.49 secs\n",
            "Step   1375: train WeightedCategoryCrossEntropy |  3.41279173\n",
            "Step   1375: eval  WeightedCategoryCrossEntropy |  3.53158116\n",
            "Step   1375: eval      WeightedCategoryAccuracy |  0.30759162\n",
            "\n",
            "Step   1380: Ran 5 train steps in 69.49 secs\n",
            "Step   1380: train WeightedCategoryCrossEntropy |  3.44232607\n",
            "Step   1380: eval  WeightedCategoryCrossEntropy |  3.40677023\n",
            "Step   1380: eval      WeightedCategoryAccuracy |  0.31763926\n",
            "\n",
            "Step   1385: Ran 5 train steps in 69.99 secs\n",
            "Step   1385: train WeightedCategoryCrossEntropy |  3.31443357\n",
            "Step   1385: eval  WeightedCategoryCrossEntropy |  3.45575476\n",
            "Step   1385: eval      WeightedCategoryAccuracy |  0.31404960\n",
            "\n",
            "Step   1390: Ran 5 train steps in 71.35 secs\n",
            "Step   1390: train WeightedCategoryCrossEntropy |  3.47007751\n",
            "Step   1390: eval  WeightedCategoryCrossEntropy |  3.46583724\n",
            "Step   1390: eval      WeightedCategoryAccuracy |  0.32232416\n",
            "\n",
            "Step   1395: Ran 5 train steps in 70.95 secs\n",
            "Step   1395: train WeightedCategoryCrossEntropy |  3.41944194\n",
            "Step   1395: eval  WeightedCategoryCrossEntropy |  3.48440552\n",
            "Step   1395: eval      WeightedCategoryAccuracy |  0.29784065\n",
            "\n",
            "Step   1400: Ran 5 train steps in 70.05 secs\n",
            "Step   1400: train WeightedCategoryCrossEntropy |  3.43381262\n",
            "Step   1400: eval  WeightedCategoryCrossEntropy |  3.52678466\n",
            "Step   1400: eval      WeightedCategoryAccuracy |  0.32871535\n",
            "\n",
            "Step   1405: Ran 5 train steps in 69.66 secs\n",
            "Step   1405: train WeightedCategoryCrossEntropy |  3.35892224\n",
            "Step   1405: eval  WeightedCategoryCrossEntropy |  3.35127711\n",
            "Step   1405: eval      WeightedCategoryAccuracy |  0.31653747\n",
            "\n",
            "Step   1410: Ran 5 train steps in 68.93 secs\n",
            "Step   1410: train WeightedCategoryCrossEntropy |  3.36278796\n",
            "Step   1410: eval  WeightedCategoryCrossEntropy |  3.25007010\n",
            "Step   1410: eval      WeightedCategoryAccuracy |  0.32682195\n",
            "\n",
            "Step   1415: Ran 5 train steps in 69.41 secs\n",
            "Step   1415: train WeightedCategoryCrossEntropy |  3.29360890\n",
            "Step   1415: eval  WeightedCategoryCrossEntropy |  3.41054320\n",
            "Step   1415: eval      WeightedCategoryAccuracy |  0.32477063\n",
            "\n",
            "Step   1420: Ran 5 train steps in 69.65 secs\n",
            "Step   1420: train WeightedCategoryCrossEntropy |  3.34771681\n",
            "Step   1420: eval  WeightedCategoryCrossEntropy |  3.32174563\n",
            "Step   1420: eval      WeightedCategoryAccuracy |  0.32643408\n",
            "\n",
            "Step   1425: Ran 5 train steps in 70.90 secs\n",
            "Step   1425: train WeightedCategoryCrossEntropy |  3.31362200\n",
            "Step   1425: eval  WeightedCategoryCrossEntropy |  3.38732100\n",
            "Step   1425: eval      WeightedCategoryAccuracy |  0.31198537\n",
            "\n",
            "Step   1430: Ran 5 train steps in 69.79 secs\n",
            "Step   1430: train WeightedCategoryCrossEntropy |  3.33284807\n",
            "Step   1430: eval  WeightedCategoryCrossEntropy |  3.32017446\n",
            "Step   1430: eval      WeightedCategoryAccuracy |  0.31560028\n",
            "\n",
            "Step   1435: Ran 5 train steps in 69.90 secs\n",
            "Step   1435: train WeightedCategoryCrossEntropy |  3.34757662\n",
            "Step   1435: eval  WeightedCategoryCrossEntropy |  3.28168774\n",
            "Step   1435: eval      WeightedCategoryAccuracy |  0.33570966\n",
            "\n",
            "Step   1440: Ran 5 train steps in 79.74 secs\n",
            "Step   1440: train WeightedCategoryCrossEntropy |  3.50602961\n",
            "Step   1440: eval  WeightedCategoryCrossEntropy |  3.47800732\n",
            "Step   1440: eval      WeightedCategoryAccuracy |  0.30305132\n",
            "\n",
            "Step   1445: Ran 5 train steps in 71.30 secs\n",
            "Step   1445: train WeightedCategoryCrossEntropy |  3.33864832\n",
            "Step   1445: eval  WeightedCategoryCrossEntropy |  3.42130065\n",
            "Step   1445: eval      WeightedCategoryAccuracy |  0.32222223\n",
            "\n",
            "Step   1450: Ran 5 train steps in 71.23 secs\n",
            "Step   1450: train WeightedCategoryCrossEntropy |  3.33300018\n",
            "Step   1450: eval  WeightedCategoryCrossEntropy |  3.17459440\n",
            "Step   1450: eval      WeightedCategoryAccuracy |  0.33958334\n",
            "\n",
            "Step   1455: Ran 5 train steps in 73.13 secs\n",
            "Step   1455: train WeightedCategoryCrossEntropy |  3.29000783\n",
            "Step   1455: eval  WeightedCategoryCrossEntropy |  3.21058798\n",
            "Step   1455: eval      WeightedCategoryAccuracy |  0.32704404\n",
            "\n",
            "Step   1460: Ran 5 train steps in 75.51 secs\n",
            "Step   1460: train WeightedCategoryCrossEntropy |  3.26828647\n",
            "Step   1460: eval  WeightedCategoryCrossEntropy |  3.24017167\n",
            "Step   1460: eval      WeightedCategoryAccuracy |  0.33699635\n",
            "\n",
            "Step   1465: Ran 5 train steps in 72.43 secs\n",
            "Step   1465: train WeightedCategoryCrossEntropy |  3.39364004\n",
            "Step   1465: eval  WeightedCategoryCrossEntropy |  3.09132814\n",
            "Step   1465: eval      WeightedCategoryAccuracy |  0.33587205\n",
            "\n",
            "Step   1470: Ran 5 train steps in 71.43 secs\n",
            "Step   1470: train WeightedCategoryCrossEntropy |  3.31659055\n",
            "Step   1470: eval  WeightedCategoryCrossEntropy |  3.36759806\n",
            "Step   1470: eval      WeightedCategoryAccuracy |  0.32358938\n",
            "\n",
            "Step   1475: Ran 5 train steps in 70.34 secs\n",
            "Step   1475: train WeightedCategoryCrossEntropy |  3.37362981\n",
            "Step   1475: eval  WeightedCategoryCrossEntropy |  3.42397094\n",
            "Step   1475: eval      WeightedCategoryAccuracy |  0.30858678\n",
            "\n",
            "Step   1480: Ran 5 train steps in 71.67 secs\n",
            "Step   1480: train WeightedCategoryCrossEntropy |  3.37416601\n",
            "Step   1480: eval  WeightedCategoryCrossEntropy |  3.45410895\n",
            "Step   1480: eval      WeightedCategoryAccuracy |  0.30660644\n",
            "\n",
            "Step   1485: Ran 5 train steps in 70.19 secs\n",
            "Step   1485: train WeightedCategoryCrossEntropy |  3.42360067\n",
            "Step   1485: eval  WeightedCategoryCrossEntropy |  3.39473295\n",
            "Step   1485: eval      WeightedCategoryAccuracy |  0.31986970\n",
            "\n",
            "Step   1490: Ran 5 train steps in 71.14 secs\n",
            "Step   1490: train WeightedCategoryCrossEntropy |  3.33038139\n",
            "Step   1490: eval  WeightedCategoryCrossEntropy |  3.41191292\n",
            "Step   1490: eval      WeightedCategoryAccuracy |  0.33203429\n",
            "\n",
            "Step   1495: Ran 5 train steps in 70.24 secs\n",
            "Step   1495: train WeightedCategoryCrossEntropy |  3.28443670\n",
            "Step   1495: eval  WeightedCategoryCrossEntropy |  3.35058188\n",
            "Step   1495: eval      WeightedCategoryAccuracy |  0.34381014\n",
            "\n",
            "Step   1500: Ran 5 train steps in 71.16 secs\n",
            "Step   1500: train WeightedCategoryCrossEntropy |  3.39258313\n",
            "Step   1500: eval  WeightedCategoryCrossEntropy |  3.47583055\n",
            "Step   1500: eval      WeightedCategoryAccuracy |  0.31395349\n",
            "\n",
            "Step   1505: Ran 5 train steps in 70.43 secs\n",
            "Step   1505: train WeightedCategoryCrossEntropy |  3.31076670\n",
            "Step   1505: eval  WeightedCategoryCrossEntropy |  3.34453201\n",
            "Step   1505: eval      WeightedCategoryAccuracy |  0.32509506\n",
            "\n",
            "Step   1510: Ran 5 train steps in 70.61 secs\n",
            "Step   1510: train WeightedCategoryCrossEntropy |  3.43316460\n",
            "Step   1510: eval  WeightedCategoryCrossEntropy |  3.30358696\n",
            "Step   1510: eval      WeightedCategoryAccuracy |  0.32633865\n",
            "\n",
            "Step   1515: Ran 5 train steps in 70.24 secs\n",
            "Step   1515: train WeightedCategoryCrossEntropy |  3.37654567\n",
            "Step   1515: eval  WeightedCategoryCrossEntropy |  3.30303311\n",
            "Step   1515: eval      WeightedCategoryAccuracy |  0.31729323\n",
            "\n",
            "Step   1520: Ran 5 train steps in 70.26 secs\n",
            "Step   1520: train WeightedCategoryCrossEntropy |  3.40453267\n",
            "Step   1520: eval  WeightedCategoryCrossEntropy |  3.27068639\n",
            "Step   1520: eval      WeightedCategoryAccuracy |  0.33006993\n",
            "\n",
            "Step   1525: Ran 5 train steps in 69.97 secs\n",
            "Step   1525: train WeightedCategoryCrossEntropy |  3.27072597\n",
            "Step   1525: eval  WeightedCategoryCrossEntropy |  3.54559302\n",
            "Step   1525: eval      WeightedCategoryAccuracy |  0.32951289\n",
            "\n",
            "Step   1530: Ran 5 train steps in 70.20 secs\n",
            "Step   1530: train WeightedCategoryCrossEntropy |  3.35639048\n",
            "Step   1530: eval  WeightedCategoryCrossEntropy |  3.40941882\n",
            "Step   1530: eval      WeightedCategoryAccuracy |  0.32300541\n",
            "\n",
            "Step   1535: Ran 5 train steps in 69.88 secs\n",
            "Step   1535: train WeightedCategoryCrossEntropy |  3.26009560\n",
            "Step   1535: eval  WeightedCategoryCrossEntropy |  3.24557686\n",
            "Step   1535: eval      WeightedCategoryAccuracy |  0.33053222\n",
            "\n",
            "Step   1540: Ran 5 train steps in 70.11 secs\n",
            "Step   1540: train WeightedCategoryCrossEntropy |  3.28833461\n",
            "Step   1540: eval  WeightedCategoryCrossEntropy |  3.38485122\n",
            "Step   1540: eval      WeightedCategoryAccuracy |  0.33154669\n",
            "\n",
            "Step   1545: Ran 5 train steps in 69.64 secs\n",
            "Step   1545: train WeightedCategoryCrossEntropy |  3.29102635\n",
            "Step   1545: eval  WeightedCategoryCrossEntropy |  3.46597362\n",
            "Step   1545: eval      WeightedCategoryAccuracy |  0.30301338\n",
            "\n",
            "Step   1550: Ran 5 train steps in 69.43 secs\n",
            "Step   1550: train WeightedCategoryCrossEntropy |  3.35756040\n",
            "Step   1550: eval  WeightedCategoryCrossEntropy |  3.26821065\n",
            "Step   1550: eval      WeightedCategoryAccuracy |  0.31532103\n",
            "\n",
            "Step   1555: Ran 5 train steps in 71.92 secs\n",
            "Step   1555: train WeightedCategoryCrossEntropy |  3.33736157\n",
            "Step   1555: eval  WeightedCategoryCrossEntropy |  3.23029089\n",
            "Step   1555: eval      WeightedCategoryAccuracy |  0.33108109\n",
            "\n",
            "Step   1560: Ran 5 train steps in 70.41 secs\n",
            "Step   1560: train WeightedCategoryCrossEntropy |  3.28584480\n",
            "Step   1560: eval  WeightedCategoryCrossEntropy |  3.33655405\n",
            "Step   1560: eval      WeightedCategoryAccuracy |  0.35031348\n",
            "\n",
            "Step   1565: Ran 5 train steps in 69.22 secs\n",
            "Step   1565: train WeightedCategoryCrossEntropy |  3.32120442\n",
            "Step   1565: eval  WeightedCategoryCrossEntropy |  3.27972341\n",
            "Step   1565: eval      WeightedCategoryAccuracy |  0.32326698\n",
            "\n",
            "Step   1570: Ran 5 train steps in 68.59 secs\n",
            "Step   1570: train WeightedCategoryCrossEntropy |  3.31153727\n",
            "Step   1570: eval  WeightedCategoryCrossEntropy |  3.20884609\n",
            "Step   1570: eval      WeightedCategoryAccuracy |  0.35543278\n",
            "\n",
            "Step   1575: Ran 5 train steps in 68.17 secs\n",
            "Step   1575: train WeightedCategoryCrossEntropy |  3.30503774\n",
            "Step   1575: eval  WeightedCategoryCrossEntropy |  3.29121804\n",
            "Step   1575: eval      WeightedCategoryAccuracy |  0.30801988\n",
            "\n",
            "Step   1580: Ran 5 train steps in 69.05 secs\n",
            "Step   1580: train WeightedCategoryCrossEntropy |  3.29732704\n",
            "Step   1580: eval  WeightedCategoryCrossEntropy |  3.27534986\n",
            "Step   1580: eval      WeightedCategoryAccuracy |  0.33365020\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xwrqA8Waagq"
      },
      "source": [
        "# Part 5:   Decode from a pretrained model\n",
        "\n",
        "The decoding is proceeded on using the model architecture just implemented. The [autoregressive_sample_stream()](https://trax-ml.readthedocs.io/en/latest/trax.supervised.html#trax.supervised.decoding.autoregressive_sample_stream) decoding method from Trax is used to do fast inference. Let's define a few parameters to initialize our model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAGnUsF_ZFl4"
      },
      "source": [
        "# define the `predict_mem_len` and `predict_drop_len` of tl.SelfAttention\n",
        "def attention(*args, **kwargs):\n",
        "    # number of input positions to remember in a cache when doing fast inference. \n",
        "    kwargs['predict_mem_len'] = 128\n",
        "    # number of input elements to drop once the fast inference input cache fills up.\n",
        "    kwargs['predict_drop_len'] = 128\n",
        "    # return the attention layer with the parameters defined above\n",
        "    return tl.SelfAttention(*args, **kwargs)\n",
        "\n",
        "# define the model using the ReformerLM function you implemented earlier.\n",
        "model = ReformerLM(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    n_layers=N_LAYERS,\n",
        "    mode='predict',\n",
        "    attention_type=attention,\n",
        ")\n",
        "\n",
        "# TRAX needs the model to be initialized with this shape\n",
        "# define an input signature so we can initialize our model. shape will be (1, 1) and the data type is int32.\n",
        "shape11 = trax.shapes.ShapeDtype((1, 1), dtype=np.int32)\n",
        "model.init(shape11)\n",
        "\n",
        "# Loading weights from the trained model\n",
        "model.weights = loop.eval_model.weights\n",
        "\n",
        "# saving the starting state for each new dialogue prediction\n",
        "STARTING_STATE = model.state"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qU-R8MvbyLyw"
      },
      "source": [
        "str(model) == str(loop.eval_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DicAPCO4at-p"
      },
      "source": [
        "def tokenize(sentence, vocab_file, vocab_dir):\n",
        "    return list(trax.data.tokenize(iter([sentence]), vocab_file=vocab_file, vocab_dir=vocab_dir))[0]\n",
        "\n",
        "def detokenize(tokens, vocab_file, vocab_dir):\n",
        "    return trax.data.detokenize(tokens, vocab_file=vocab_file, vocab_dir=vocab_dir)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWQB5krValEY"
      },
      "source": [
        "# # initialize from file\n",
        "# model.init_from_file('chatbot_model1.pkl.gz',\n",
        "#                      weights_only=True, input_signature=shape11)\n",
        "\n",
        "# # save the starting state\n",
        "# STARTING_STATE = model.state"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gxt2HbXWnVCn"
      },
      "source": [
        "def ReformerLM_output_gen(ReformerLM, start_sentence, vocab_file, vocab_dir, temperature):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        ReformerLM:  the Reformer language model you just trained\n",
        "        start_sentence (string): starting sentence of the conversation\n",
        "        vocab_file (string): vocabulary filename\n",
        "        vocab_dir (string): directory of the vocabulary file\n",
        "        temperature (float): parameter for sampling ranging from 0.0 to 1.0.\n",
        "            0.0: same as argmax, always pick the most probable token\n",
        "            1.0: sampling from the distribution (can sometimes say random things)\n",
        "\n",
        "    Returns:\n",
        "        generator: yields the next symbol generated by the model\n",
        "    \"\"\"\n",
        "    \n",
        "    # Create input tokens using the the tokenize function\n",
        "    input_tokens = tokenize(start_sentence, vocab_file, vocab_dir)\n",
        "    \n",
        "    # Add batch dimension to array. Convert from (n,) to (x, n) where \n",
        "    # x is the batch size. Default is 1. (hint: you can use np.expand_dims() with axis=0)\n",
        "    input_tokens_with_batch = input_tokens[None]\n",
        "    \n",
        "    # call the autoregressive_sample_stream function from trax\n",
        "    output_gen = trax.supervised.decoding.autoregressive_sample_stream( \n",
        "        # model\n",
        "        model = ReformerLM,\n",
        "        # inputs will be the tokens with batch dimension\n",
        "        inputs = input_tokens_with_batch,\n",
        "        # temperature\n",
        "        temperature = temperature\n",
        "    )\n",
        "    return output_gen"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9l_huH81S7P"
      },
      "source": [
        "def generate_dialogue(ReformerLM, model_state, start_sentence, vocab_file, vocab_dir, max_len, temperature):\n",
        "    delimiter_1 = 'Person 1: ' \n",
        "    delimiter_2 = 'Person 2: '\n",
        "    sentence = ''\n",
        "    counter = 0\n",
        "    \n",
        "    result = [tokenize(': ', vocab_file=vocab_file, vocab_dir=vocab_dir)]\n",
        "    \n",
        "    ReformerLM.state = model_state\n",
        "    \n",
        "    output = ReformerLM_output_gen(ReformerLM, start_sentence, vocab_file=VOCAB_FILE, vocab_dir=VOCAB_DIR, temperature=temperature)\n",
        "    \n",
        "    print(colored(start_sentence.split(delimiter_2)[0].strip(), 'green'))\n",
        "    \n",
        "    for o in output:\n",
        "        result.append(o)\n",
        "        \n",
        "        sentence = detokenize(np.concatenate(result, axis=0), vocab_file=VOCAB_FILE, vocab_dir=VOCAB_DIR)\n",
        "        # print(sentence)\n",
        "        if sentence.endswith(delimiter_1):\n",
        "            sentence = sentence.split(delimiter_1)[0]\n",
        "            print(colored(f'{delimiter_2}{sentence}', 'red'))\n",
        "            sentence = ''\n",
        "            result.clear()\n",
        "        \n",
        "        elif sentence.endswith(delimiter_2):\n",
        "            sentence = sentence.split(delimiter_2)[0]\n",
        "            print(colored(f'{delimiter_1}{sentence}', 'green'))\n",
        "            sentence = ''\n",
        "            result.clear()\n",
        "\n",
        "        counter += 1\n",
        "        \n",
        "        if counter > max_len:\n",
        "            print(sentence)\n",
        "            break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yeMM66K_33w"
      },
      "source": [
        "sample_sentence = ' Person 1: Er der et hospital noget sted? Person 2: '\n",
        "generate_dialogue(ReformerLM=model, model_state=STARTING_STATE, start_sentence=sample_sentence, vocab_file=VOCAB_FILE, vocab_dir=VOCAB_DIR, max_len=200, temperature=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MPkLq8SXYcz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68cb8271-cdca-47c6-f9de-cd672d61c021"
      },
      "source": [
        "sample_sentence = ' Person 1: Er der et teater i byen? Person 2: '\n",
        "generate_dialogue(ReformerLM=model, model_state=STARTING_STATE, start_sentence=sample_sentence, vocab_file=VOCAB_FILE, vocab_dir=VOCAB_DIR, max_len=200, temperature=0.1)\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32mPerson 1: Er der et teater i byen?\u001b[0m\n",
            "\u001b[31mPerson 2: : Jeg ji centrum byen. Jeg vil du du h2230;rr\br〓2230;rcentrum \u001b[0m\n",
            "\u001b[31mPerson 2: Jeg for at du hfor du du du du du have. \u001b[0m\n",
            "Jeg har du du du du du du du du du du du du du du du du du du du du du du du du du vil du du du du du du du du du du du du du hjࢵr〓;;;;230;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;2230;;30;;;;;30;230;;;;;;;;;;;;;;;;230;;;;\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c09h5Akq59g8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3e0c623-9522-4213-efbf-69fe1146d9ce"
      },
      "source": [
        "sample_sentence = ' Person 1: Kan du reservere en taxa? Person 2: '\n",
        "generate_dialogue(ReformerLM=model, model_state=STARTING_STATE, start_sentence=sample_sentence, vocab_file=VOCAB_FILE, vocab_dir=VOCAB_DIR, max_len=200, temperature=0.1)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32mPerson 1: Kan du reservere en taxa?\u001b[0m\n",
            "\u001b[31mPerson 2: : Jeg har brug for at du finde at du finde at finde et et sted? \u001b[0m\n",
            "\u001b[32mPerson 1: Jeg vil du du finde at du du du du du du du du hj〓r\u001b[0m\n",
            "\u001b[31mPerson 2: Jeg vil du du have? \u001b[0m\n",
            "\u001b[31mPerson 2: Jeg har efter mig. Jeg har brug for at du du have? \u001b[0m\n",
            "\u001b[31mPerson 2: Jeg vil du du har brug for? \u001b[0m\n",
            "Jeg vil du du du du du hjࢶrࢵ230;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;30;230;;;;;230;;;;;;;;;;;;;;;;;;;;;230;;;\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tN-wHDL263Uj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}